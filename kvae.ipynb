{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "from kvae_model import KVAEModel\r\n",
    "from kvae import KVAE\r\n",
    "from tqdm import tqdm\r\n",
    "import pickle\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "batch_size = 80\r\n",
    "train_dataset, val_dataset =  load_bouncing_ball(\"bouncing_ball_data\", \"box\")\r\n",
    "train_dataset = train_dataset[np.random.choice(5000, 800)]\r\n",
    "val_dataset = val_dataset[np.random.choice(1000, 400)]\r\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = False, num_workers = 6)\r\n",
    "val_dataloader   = torch.utils.data.DataLoader(val_dataset,   batch_size=batch_size, shuffle = False, num_workers = 6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model = KVAEModel(x_dim = 32 * 32, \r\n",
    "             a_dim = 32,\r\n",
    "             z_dim = 16, \r\n",
    "             dense_x_a = [256,128],\r\n",
    "             dense_a_x = [128,256],\r\n",
    "             x_2d=True,\r\n",
    "\r\n",
    "             init_kf_mat = 0.05,\r\n",
    "             noise_transition = 0.08,\r\n",
    "             noise_emission = 0.03,\r\n",
    "             init_cov = 20,\r\n",
    "\r\n",
    "             K = 10,\r\n",
    "             dim_RNN_alpha = 50,\r\n",
    "             num_RNN_alpha = 1,\r\n",
    "             dropout_p = 0,\r\n",
    "             scale_reconstruction = 1,\r\n",
    "             device='cpu').to('cpu')\r\n",
    "model.build()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('A', Parameter containing:\n",
      "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]]], requires_grad=True))\n",
      "('B', Parameter containing:\n",
      "tensor([[[-1.5613e-02,  6.4227e-02, -1.5961e-02,  ..., -4.1225e-02,\n",
      "           5.1137e-03, -1.3349e-02],\n",
      "         [-6.7348e-02,  5.7097e-03, -3.2677e-02,  ...,  8.4410e-02,\n",
      "          -3.7038e-02,  7.6635e-02],\n",
      "         [-2.8910e-02,  2.2551e-02,  2.9612e-02,  ..., -3.4976e-02,\n",
      "          -1.6789e-03,  4.5666e-02],\n",
      "         ...,\n",
      "         [ 5.0414e-03,  3.3124e-02, -3.4476e-02,  ...,  5.3667e-02,\n",
      "          -3.7945e-02, -1.1995e-03],\n",
      "         [-2.4530e-02, -3.4859e-02, -4.8019e-02,  ...,  6.4950e-02,\n",
      "           4.2709e-02,  2.2220e-02],\n",
      "         [ 2.2363e-02,  7.8757e-03, -2.5946e-02,  ..., -1.7417e-02,\n",
      "           5.5566e-02, -1.2707e-02]],\n",
      "\n",
      "        [[-4.9291e-02,  5.7285e-02,  4.5814e-02,  ...,  8.0770e-05,\n",
      "           4.9305e-02,  8.8840e-03],\n",
      "         [-7.3808e-02, -2.5142e-02,  2.9780e-02,  ..., -3.8376e-02,\n",
      "           1.0840e-01,  3.9972e-02],\n",
      "         [-3.7252e-03,  1.4394e-02,  1.3750e-02,  ...,  7.3243e-02,\n",
      "           8.8289e-03,  5.5311e-02],\n",
      "         ...,\n",
      "         [ 3.4913e-04,  7.1863e-02, -1.0766e-01,  ...,  9.7875e-02,\n",
      "           9.3511e-02,  8.0347e-02],\n",
      "         [-4.6141e-03,  6.7270e-02,  7.2158e-02,  ..., -4.4292e-02,\n",
      "           2.5043e-02,  3.9105e-02],\n",
      "         [-8.4231e-02,  1.6144e-02,  1.3542e-04,  ..., -3.3701e-02,\n",
      "           3.1893e-02,  8.0997e-03]],\n",
      "\n",
      "        [[-2.6163e-02, -1.2158e-01, -4.7220e-04,  ..., -2.5513e-02,\n",
      "          -8.5222e-03, -8.5033e-02],\n",
      "         [-3.5327e-02, -2.3466e-02,  2.6062e-03,  ..., -2.4581e-02,\n",
      "          -6.7275e-02,  1.0937e-02],\n",
      "         [ 4.1831e-02, -4.5847e-04,  8.4148e-02,  ..., -4.8652e-02,\n",
      "          -3.2052e-02,  2.9934e-02],\n",
      "         ...,\n",
      "         [-2.0476e-03, -3.6193e-02, -5.3723e-02,  ..., -3.8756e-02,\n",
      "          -5.3745e-03,  5.1860e-02],\n",
      "         [-6.3408e-02, -2.9617e-02, -2.1360e-02,  ...,  1.9370e-02,\n",
      "          -2.9009e-02,  8.9325e-02],\n",
      "         [-8.5547e-02, -7.5576e-04, -3.9400e-02,  ..., -3.7992e-02,\n",
      "          -1.8904e-02,  8.0754e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.5077e-02,  1.8323e-02, -1.3366e-02,  ...,  1.5413e-02,\n",
      "           1.6417e-02,  8.2127e-02],\n",
      "         [ 4.7402e-02, -8.1519e-02,  1.7008e-01,  ..., -1.0813e-01,\n",
      "          -8.1163e-02, -3.3366e-02],\n",
      "         [ 1.8823e-02, -9.5770e-03, -4.8900e-02,  ...,  2.7057e-02,\n",
      "          -4.5073e-02,  1.0183e-01],\n",
      "         ...,\n",
      "         [ 3.7758e-02, -1.8312e-02,  1.4142e-02,  ..., -1.1283e-03,\n",
      "          -4.3903e-03,  3.9151e-02],\n",
      "         [-3.7857e-02, -3.4123e-02, -2.4300e-02,  ..., -5.2765e-02,\n",
      "           4.4872e-02, -5.3350e-02],\n",
      "         [ 2.5842e-02, -2.2235e-02, -4.3538e-03,  ..., -5.4337e-03,\n",
      "          -3.2950e-02,  4.4029e-02]],\n",
      "\n",
      "        [[-2.1179e-02, -5.6697e-04, -8.9804e-02,  ..., -5.4732e-03,\n",
      "          -1.3781e-02,  5.9947e-02],\n",
      "         [ 1.4922e-02, -6.5554e-02,  1.6379e-02,  ...,  2.0726e-03,\n",
      "          -6.1914e-02, -6.3907e-03],\n",
      "         [-2.5664e-02,  8.8867e-03, -3.1509e-02,  ...,  2.1636e-02,\n",
      "          -6.0688e-02,  1.7265e-02],\n",
      "         ...,\n",
      "         [ 4.2216e-02,  2.3944e-02, -5.4491e-02,  ...,  4.9599e-02,\n",
      "           1.3888e-01,  2.4305e-02],\n",
      "         [ 1.1558e-01, -1.8650e-02,  7.5061e-02,  ..., -8.1524e-03,\n",
      "          -3.7554e-02, -1.0702e-01],\n",
      "         [-8.9561e-03, -1.9714e-03, -3.0282e-02,  ...,  2.6884e-03,\n",
      "           2.2234e-03, -1.3029e-02]],\n",
      "\n",
      "        [[ 5.4908e-02,  6.2020e-02, -5.3753e-03,  ...,  3.6464e-03,\n",
      "           1.2484e-01,  4.6092e-02],\n",
      "         [ 2.0891e-02, -4.6192e-02, -1.7615e-02,  ..., -4.3100e-03,\n",
      "          -5.6049e-03, -8.0978e-02],\n",
      "         [-8.0030e-02, -9.7704e-02, -1.3866e-02,  ..., -4.4272e-03,\n",
      "          -8.2526e-02,  6.6963e-02],\n",
      "         ...,\n",
      "         [ 7.1068e-02, -1.4648e-02,  8.9283e-02,  ...,  2.8584e-02,\n",
      "          -3.6736e-04,  8.9218e-02],\n",
      "         [ 7.9092e-02,  2.5260e-02, -1.8985e-02,  ...,  3.2024e-02,\n",
      "          -3.9005e-02,  7.6757e-02],\n",
      "         [-6.3847e-02,  9.6461e-03, -6.8709e-02,  ...,  4.3349e-02,\n",
      "          -4.5419e-02, -3.2894e-02]]], requires_grad=True))\n",
      "('C', Parameter containing:\n",
      "tensor([[[-0.0154, -0.0033, -0.1510,  ...,  0.0044, -0.0153, -0.0213],\n",
      "         [-0.0846,  0.0341, -0.0623,  ...,  0.0523, -0.0450,  0.0233],\n",
      "         [-0.0657,  0.0023, -0.0495,  ...,  0.0215, -0.0874, -0.0576],\n",
      "         ...,\n",
      "         [-0.0505, -0.0203,  0.0645,  ...,  0.0694, -0.0120,  0.0376],\n",
      "         [ 0.0476,  0.0403,  0.0030,  ..., -0.0081,  0.0007,  0.0178],\n",
      "         [ 0.0486,  0.0983, -0.0304,  ..., -0.0959, -0.0598, -0.0823]],\n",
      "\n",
      "        [[-0.0338,  0.0314,  0.0363,  ..., -0.1014,  0.0283, -0.0287],\n",
      "         [ 0.0003,  0.0058,  0.0501,  ...,  0.0049, -0.0027, -0.0336],\n",
      "         [-0.0658,  0.0465, -0.0607,  ..., -0.0515,  0.0349,  0.0869],\n",
      "         ...,\n",
      "         [-0.0364,  0.0026, -0.0369,  ..., -0.0188, -0.1233,  0.0456],\n",
      "         [-0.0228,  0.0416,  0.0160,  ..., -0.0034,  0.0340, -0.0019],\n",
      "         [ 0.0198, -0.0868,  0.0571,  ...,  0.0070, -0.0025,  0.0039]],\n",
      "\n",
      "        [[-0.1585, -0.0497, -0.0567,  ...,  0.0589,  0.0012, -0.0456],\n",
      "         [-0.0204,  0.0471,  0.0192,  ...,  0.0251,  0.0039, -0.0684],\n",
      "         [ 0.0361,  0.0133, -0.0438,  ..., -0.0040, -0.0234, -0.0663],\n",
      "         ...,\n",
      "         [ 0.0527,  0.0255,  0.0214,  ..., -0.0191, -0.0327, -0.0367],\n",
      "         [ 0.0080, -0.0023, -0.0031,  ..., -0.0482,  0.0242, -0.0116],\n",
      "         [-0.0003, -0.0302,  0.0238,  ...,  0.0927,  0.0217, -0.0371]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0330, -0.0800, -0.0585,  ...,  0.0762, -0.0010,  0.0853],\n",
      "         [-0.0480,  0.0554,  0.0753,  ..., -0.0964,  0.0495, -0.0434],\n",
      "         [-0.0237, -0.0187, -0.1095,  ..., -0.0527,  0.0335,  0.0197],\n",
      "         ...,\n",
      "         [ 0.0514,  0.0099, -0.0336,  ..., -0.0288, -0.0857, -0.0331],\n",
      "         [ 0.0079,  0.0263,  0.0745,  ...,  0.0934, -0.0253,  0.0453],\n",
      "         [-0.1208,  0.0081, -0.0309,  ...,  0.0105, -0.0300,  0.0724]],\n",
      "\n",
      "        [[-0.0803, -0.0302,  0.0207,  ..., -0.0106, -0.0629,  0.0425],\n",
      "         [-0.0261, -0.1131,  0.0544,  ..., -0.0502, -0.0216,  0.0753],\n",
      "         [-0.0273,  0.0055, -0.0802,  ...,  0.0057, -0.0255, -0.0232],\n",
      "         ...,\n",
      "         [-0.0929,  0.0286, -0.0794,  ..., -0.0037,  0.0690,  0.0579],\n",
      "         [ 0.0559, -0.0288, -0.0960,  ...,  0.0076, -0.0671, -0.0035],\n",
      "         [-0.0161, -0.0721, -0.0217,  ..., -0.0301,  0.0039,  0.0789]],\n",
      "\n",
      "        [[ 0.0304, -0.0386, -0.0703,  ...,  0.0341,  0.0006, -0.0709],\n",
      "         [ 0.0544, -0.0520, -0.0097,  ..., -0.0037,  0.0451,  0.0646],\n",
      "         [ 0.0391,  0.0081,  0.0025,  ...,  0.0100, -0.0692, -0.0397],\n",
      "         ...,\n",
      "         [-0.0560,  0.0083,  0.0038,  ..., -0.0203, -0.0267,  0.0415],\n",
      "         [ 0.0377,  0.0255, -0.0490,  ...,  0.1413,  0.0963, -0.0031],\n",
      "         [-0.0334, -0.0815,  0.0098,  ..., -0.0127,  0.0886, -0.0786]]],\n",
      "       requires_grad=True))\n",
      "('a_init', Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True))\n",
      "('mlp_x_a.linear0.weight', Parameter containing:\n",
      "tensor([[ 0.0060,  0.0155, -0.0173,  ..., -0.0102,  0.0105, -0.0145],\n",
      "        [ 0.0029,  0.0125, -0.0010,  ...,  0.0117,  0.0093, -0.0251],\n",
      "        [ 0.0254, -0.0097, -0.0176,  ..., -0.0304,  0.0182,  0.0235],\n",
      "        ...,\n",
      "        [-0.0062,  0.0244,  0.0093,  ...,  0.0040, -0.0144, -0.0246],\n",
      "        [ 0.0036, -0.0205, -0.0212,  ...,  0.0072,  0.0030, -0.0055],\n",
      "        [-0.0258, -0.0014, -0.0130,  ...,  0.0007, -0.0173, -0.0221]],\n",
      "       requires_grad=True))\n",
      "('mlp_x_a.linear0.bias', Parameter containing:\n",
      "tensor([ 3.1301e-03, -2.3596e-02, -5.6232e-03,  2.6795e-02, -1.7996e-02,\n",
      "        -2.2708e-02,  1.3725e-02,  4.3984e-03, -2.2994e-02,  2.1970e-02,\n",
      "        -3.3051e-03,  2.2491e-02,  1.2181e-02, -8.8386e-03, -6.7065e-03,\n",
      "         2.3033e-02, -9.5789e-03, -1.7263e-02, -1.2607e-02,  2.9421e-02,\n",
      "        -1.3711e-02, -8.5130e-03, -2.3286e-02, -1.8727e-02,  9.2411e-03,\n",
      "        -1.9299e-02,  2.0052e-02, -2.5043e-02,  1.2839e-03,  1.4761e-02,\n",
      "         3.0576e-02, -1.6887e-02, -6.1500e-03,  2.7800e-02,  2.9569e-02,\n",
      "        -1.2621e-02,  2.6308e-02,  3.0484e-02, -2.8690e-02,  2.2089e-02,\n",
      "         4.5363e-03, -1.0302e-02, -8.7024e-03, -3.3186e-04, -2.3150e-02,\n",
      "         2.1608e-02, -4.1637e-03,  5.1491e-03, -1.2194e-02, -2.0928e-02,\n",
      "         3.0505e-02, -1.7147e-02,  2.0364e-02, -1.3099e-03,  9.3978e-05,\n",
      "        -7.8731e-03, -2.6582e-02, -6.7566e-03,  2.0931e-02,  1.6092e-02,\n",
      "        -2.2382e-05,  6.8508e-03, -7.9546e-04,  1.9995e-02, -1.1238e-02,\n",
      "        -1.8155e-02,  1.7290e-02, -1.3737e-02, -1.1300e-02,  1.1540e-02,\n",
      "        -6.5683e-03,  1.2990e-02,  1.9831e-02,  1.9679e-02, -3.8317e-03,\n",
      "         1.4619e-02,  2.3630e-04, -1.3502e-02,  2.5954e-02, -2.9445e-02,\n",
      "        -2.7975e-02, -4.1215e-03, -3.1135e-02,  2.5371e-02, -9.1279e-03,\n",
      "        -9.5054e-03, -4.0727e-03,  2.6891e-03,  2.7953e-02,  2.8694e-02,\n",
      "        -8.4327e-03,  1.6604e-02,  2.1495e-02, -6.1790e-03,  2.1895e-02,\n",
      "        -8.8929e-03, -3.8241e-03,  3.3427e-03,  1.0001e-04, -2.0326e-03,\n",
      "        -2.9986e-02,  1.5444e-02, -1.6890e-02,  2.7964e-02, -2.5355e-03,\n",
      "         1.1041e-02,  8.2346e-03,  1.8839e-02, -2.2634e-02, -2.3278e-02,\n",
      "         1.3665e-02,  1.4795e-03, -2.4128e-02, -2.1463e-02,  1.6152e-03,\n",
      "        -9.3642e-03, -2.0865e-02,  2.3353e-02,  5.6677e-03,  1.1789e-02,\n",
      "        -1.7241e-02,  1.7752e-03, -1.0715e-02,  1.5461e-02, -1.8053e-02,\n",
      "         1.3874e-02,  7.4767e-03,  2.4335e-02,  2.6988e-02, -1.9182e-02,\n",
      "        -1.4833e-02,  1.0003e-02, -1.6348e-02, -1.5603e-02, -2.0871e-02,\n",
      "        -1.0375e-03, -1.7155e-02,  6.0061e-03,  2.5361e-03,  2.9415e-02,\n",
      "         1.5503e-02,  1.0007e-03,  1.2039e-02,  2.5944e-02, -7.5324e-03,\n",
      "        -6.8497e-03,  2.4113e-02,  1.2542e-02, -1.6305e-02,  2.7217e-02,\n",
      "         1.4239e-02,  3.5302e-03, -9.1421e-03,  1.1048e-02,  2.5503e-02,\n",
      "         2.3022e-02,  1.0278e-02,  1.8083e-02,  2.2566e-02, -7.7624e-03,\n",
      "        -1.8156e-02, -1.4140e-02,  1.7846e-02, -2.8489e-02,  1.1549e-02,\n",
      "         2.8555e-02,  1.0958e-02, -1.4326e-02,  8.2211e-03,  4.1691e-03,\n",
      "         2.1043e-02, -1.0765e-03, -4.4574e-03, -4.1432e-03, -1.5327e-02,\n",
      "         2.5983e-02, -1.5958e-02, -2.6374e-02, -1.7483e-02, -1.6622e-02,\n",
      "         6.8288e-04,  1.1581e-02,  1.9864e-02,  1.2026e-02,  4.3100e-03,\n",
      "        -2.9619e-02,  8.3034e-04, -3.0156e-02,  2.6156e-03,  1.0606e-02,\n",
      "         8.6385e-03,  1.1360e-02, -2.0930e-02,  1.7448e-02, -2.8862e-02,\n",
      "         1.3961e-02, -1.5363e-02,  1.5559e-02, -2.0722e-02, -2.6198e-02,\n",
      "        -1.1662e-02, -4.0584e-03,  2.7323e-02, -3.0781e-02,  1.3759e-02,\n",
      "        -9.8459e-04, -1.7345e-02,  2.2058e-02,  4.8353e-03,  6.0964e-03,\n",
      "        -1.5412e-02, -2.8535e-02, -1.8172e-02,  4.2564e-03,  1.8710e-02,\n",
      "        -1.7290e-02, -2.9799e-02,  3.4695e-03, -2.1383e-02, -1.1343e-02,\n",
      "         2.7088e-03,  7.2660e-03, -2.8970e-02, -1.8865e-02, -2.1111e-02,\n",
      "        -1.4153e-02,  1.6844e-02,  2.7764e-02,  2.2231e-02, -1.6083e-02,\n",
      "        -2.6143e-02,  1.7633e-02,  2.2931e-02,  1.8152e-02,  1.6984e-02,\n",
      "        -1.5191e-02,  1.1763e-02, -1.8421e-03, -2.9010e-03, -2.0420e-02,\n",
      "        -5.2863e-04,  3.3182e-03,  7.7529e-03, -2.3763e-02, -1.8659e-02,\n",
      "        -2.1745e-02,  1.9990e-02,  2.7143e-03,  1.8279e-02, -1.3396e-02,\n",
      "         1.8097e-02, -7.7801e-03, -1.2909e-02,  1.5055e-02, -6.2842e-03,\n",
      "         1.8818e-02], requires_grad=True))\n",
      "('mlp_x_a.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0296,  0.0370, -0.0581,  ...,  0.0300, -0.0271,  0.0422],\n",
      "        [ 0.0293, -0.0120, -0.0432,  ...,  0.0419, -0.0358, -0.0293],\n",
      "        [ 0.0256,  0.0203, -0.0164,  ...,  0.0044, -0.0185, -0.0604],\n",
      "        ...,\n",
      "        [ 0.0202,  0.0200, -0.0162,  ..., -0.0364, -0.0095, -0.0437],\n",
      "        [ 0.0516, -0.0520,  0.0342,  ..., -0.0289, -0.0622,  0.0307],\n",
      "        [ 0.0260,  0.0582, -0.0526,  ...,  0.0609,  0.0541,  0.0198]],\n",
      "       requires_grad=True))\n",
      "('mlp_x_a.linear1.bias', Parameter containing:\n",
      "tensor([ 1.6599e-02, -5.8401e-02, -1.9282e-02, -3.7413e-02,  5.2216e-02,\n",
      "         1.7535e-02,  2.0871e-02, -5.7281e-02,  5.1559e-02, -3.2975e-02,\n",
      "        -2.8613e-02,  1.5588e-02,  4.3976e-02, -4.1910e-02, -4.4162e-02,\n",
      "         2.7108e-02, -6.1338e-02,  1.6501e-02, -7.0110e-03, -4.9530e-02,\n",
      "         5.0436e-02, -5.7506e-02, -5.9818e-02,  4.8251e-02,  2.2260e-02,\n",
      "         1.8792e-02,  2.2347e-02,  1.3658e-02, -4.5744e-02,  2.2820e-02,\n",
      "         3.5786e-02, -2.9602e-02, -5.5181e-02, -5.0840e-02,  5.8626e-02,\n",
      "         6.2299e-03, -1.7273e-03, -5.4968e-02, -3.6304e-02,  5.4109e-02,\n",
      "         4.3543e-02,  2.3486e-02, -3.7327e-02, -5.4551e-02,  6.1825e-02,\n",
      "         5.3748e-02, -8.3283e-03,  1.9164e-02, -1.5816e-02,  3.1946e-02,\n",
      "         3.0025e-02, -4.7451e-02, -3.9300e-02, -3.3003e-02, -1.2526e-02,\n",
      "        -8.2856e-03,  1.3856e-02,  4.4945e-02,  2.5095e-02, -1.7442e-03,\n",
      "         5.5583e-02,  1.3920e-02, -4.4668e-03, -3.7819e-03, -6.0636e-02,\n",
      "         9.6677e-04, -6.0764e-02, -4.0494e-02,  3.8632e-02,  5.1719e-02,\n",
      "        -2.4490e-02, -1.2494e-02,  1.3625e-02, -2.8601e-02,  3.6623e-02,\n",
      "        -5.0405e-02,  1.6645e-02, -5.5283e-02,  4.9064e-02,  2.2733e-02,\n",
      "         6.1167e-02,  3.7907e-02,  3.0428e-04, -6.1057e-02,  3.7781e-02,\n",
      "        -2.6891e-02, -3.6702e-02, -4.1302e-02, -2.6283e-02,  5.1845e-02,\n",
      "        -4.0280e-02,  4.7286e-02,  6.0187e-02, -6.0714e-02, -5.8339e-02,\n",
      "         3.0041e-03, -1.3501e-02, -1.6312e-02,  1.4040e-02, -7.6648e-03,\n",
      "         1.5020e-03,  4.2887e-02,  4.3069e-02,  4.5118e-02, -1.8739e-02,\n",
      "         6.0245e-05, -3.4187e-02,  2.5544e-02, -3.1117e-02, -3.6916e-02,\n",
      "        -2.1001e-02,  3.5731e-02, -3.8418e-02, -6.0405e-02,  6.1580e-02,\n",
      "         5.3316e-02, -2.9141e-02, -4.9398e-02,  2.9671e-02,  4.3399e-02,\n",
      "         3.6102e-02, -1.9202e-02, -5.9998e-03, -1.4337e-02,  1.2924e-02,\n",
      "         2.2627e-02,  5.3640e-02, -4.6976e-02], requires_grad=True))\n",
      "('inf_mean.weight', Parameter containing:\n",
      "tensor([[ 0.0276,  0.0184,  0.0671,  ..., -0.0498, -0.0774, -0.0576],\n",
      "        [ 0.0761, -0.0826,  0.0754,  ..., -0.0564, -0.0765,  0.0581],\n",
      "        [-0.0040, -0.0477,  0.0739,  ..., -0.0103,  0.0800, -0.0721],\n",
      "        ...,\n",
      "        [-0.0462,  0.0050,  0.0378,  ...,  0.0693, -0.0720,  0.0511],\n",
      "        [-0.0226,  0.0798,  0.0309,  ..., -0.0390, -0.0685, -0.0276],\n",
      "        [ 0.0256,  0.0031,  0.0020,  ...,  0.0164, -0.0486, -0.0039]],\n",
      "       requires_grad=True))\n",
      "('inf_mean.bias', Parameter containing:\n",
      "tensor([-0.0593, -0.0801,  0.0490,  0.0527, -0.0490,  0.0189, -0.0357, -0.0142,\n",
      "        -0.0118,  0.0002, -0.0293, -0.0377,  0.0444, -0.0363, -0.0838,  0.0364,\n",
      "        -0.0600,  0.0321, -0.0805, -0.0835,  0.0217, -0.0736, -0.0609, -0.0253,\n",
      "         0.0864,  0.0734,  0.0135, -0.0744, -0.0184,  0.0330,  0.0620, -0.0789],\n",
      "       requires_grad=True))\n",
      "('inf_logvar.weight', Parameter containing:\n",
      "tensor([[-0.0357, -0.0434,  0.0223,  ...,  0.0075,  0.0703,  0.0571],\n",
      "        [ 0.0071, -0.0359,  0.0776,  ..., -0.0851,  0.0532, -0.0372],\n",
      "        [ 0.0763,  0.0089, -0.0526,  ...,  0.0875,  0.0687,  0.0029],\n",
      "        ...,\n",
      "        [ 0.0035, -0.0718, -0.0461,  ..., -0.0494,  0.0154, -0.0754],\n",
      "        [ 0.0428, -0.0146, -0.0057,  ...,  0.0433, -0.0664, -0.0839],\n",
      "        [-0.0771, -0.0093, -0.0605,  ..., -0.0573, -0.0744,  0.0227]],\n",
      "       requires_grad=True))\n",
      "('inf_logvar.bias', Parameter containing:\n",
      "tensor([-0.0010,  0.0555,  0.0876,  0.0599,  0.0558,  0.0136, -0.0677, -0.0297,\n",
      "        -0.0861, -0.0406, -0.0038, -0.0359, -0.0865, -0.0643, -0.0845,  0.0839,\n",
      "         0.0535, -0.0113, -0.0646, -0.0462, -0.0614, -0.0461, -0.0060, -0.0348,\n",
      "         0.0749, -0.0761,  0.0149,  0.0652, -0.0228,  0.0556,  0.0867,  0.0005],\n",
      "       requires_grad=True))\n",
      "('mlp_a_x.linear0.weight', Parameter containing:\n",
      "tensor([[-0.1565, -0.0013,  0.1291,  ..., -0.0355, -0.0992,  0.1174],\n",
      "        [-0.1495,  0.1592,  0.0297,  ..., -0.0617, -0.0056, -0.1607],\n",
      "        [-0.1617, -0.1497, -0.1112,  ..., -0.0310, -0.1720,  0.1243],\n",
      "        ...,\n",
      "        [-0.0826,  0.1464, -0.0717,  ...,  0.1414,  0.1309,  0.0897],\n",
      "        [-0.0116,  0.1382,  0.1471,  ...,  0.0645, -0.1273,  0.0286],\n",
      "        [ 0.1613,  0.0105,  0.0675,  ...,  0.0742, -0.1272, -0.1138]],\n",
      "       requires_grad=True))\n",
      "('mlp_a_x.linear0.bias', Parameter containing:\n",
      "tensor([ 0.0456, -0.1002, -0.1751, -0.1276, -0.1162,  0.0448,  0.0538,  0.0567,\n",
      "         0.0022, -0.0662,  0.0008, -0.1050, -0.0123, -0.0992,  0.1308, -0.1021,\n",
      "        -0.1228,  0.0520,  0.1554, -0.1515,  0.0891, -0.1002, -0.1134,  0.0564,\n",
      "        -0.1547,  0.1565, -0.0815, -0.1124, -0.0555,  0.0653,  0.1666,  0.0152,\n",
      "         0.0846, -0.1454, -0.0388,  0.1356,  0.0408, -0.0513, -0.0388, -0.1349,\n",
      "         0.1689,  0.1093,  0.1189,  0.0893,  0.0075,  0.0825,  0.0804,  0.0249,\n",
      "         0.1730,  0.0776, -0.1446, -0.0822,  0.1205, -0.1188,  0.1514,  0.0018,\n",
      "        -0.1342,  0.0587,  0.0741, -0.0503,  0.0682,  0.1329, -0.0590,  0.0352,\n",
      "        -0.0549,  0.0215,  0.0444,  0.1387,  0.0078, -0.1403, -0.1183, -0.0212,\n",
      "         0.1743,  0.1318,  0.0566,  0.1171, -0.0077,  0.0259, -0.0131,  0.0556,\n",
      "         0.1659,  0.1046,  0.0783,  0.1381, -0.0817,  0.1342, -0.0784,  0.1379,\n",
      "        -0.0532,  0.0743, -0.0627,  0.1637, -0.1297,  0.0633,  0.1389, -0.1575,\n",
      "        -0.1365, -0.1714, -0.0949, -0.0663,  0.0783, -0.0580,  0.1218, -0.1390,\n",
      "         0.1360,  0.1369,  0.0934,  0.1144,  0.1203, -0.1438,  0.1542, -0.0134,\n",
      "        -0.0841,  0.1644, -0.0233, -0.0839, -0.1723,  0.1134, -0.1274, -0.1204,\n",
      "         0.1379, -0.0169, -0.1700,  0.0301, -0.1420,  0.0714,  0.0134,  0.1069],\n",
      "       requires_grad=True))\n",
      "('mlp_a_x.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0393, -0.0351,  0.0104,  ...,  0.0281, -0.0704, -0.0190],\n",
      "        [-0.0267, -0.0738,  0.0728,  ..., -0.0354,  0.0703, -0.0379],\n",
      "        [ 0.0727, -0.0180,  0.0824,  ...,  0.0223,  0.0522, -0.0706],\n",
      "        ...,\n",
      "        [ 0.0175, -0.0286, -0.0497,  ..., -0.0717,  0.0558, -0.0223],\n",
      "        [-0.0439, -0.0567, -0.0090,  ..., -0.0399,  0.0614,  0.0204],\n",
      "        [-0.0879, -0.0105, -0.0635,  ..., -0.0404, -0.0236,  0.0405]],\n",
      "       requires_grad=True))\n",
      "('mlp_a_x.linear1.bias', Parameter containing:\n",
      "tensor([ 0.0812, -0.0297,  0.0740,  0.0563, -0.0681,  0.0670,  0.0066,  0.0163,\n",
      "        -0.0433, -0.0220, -0.0789, -0.0358, -0.0433, -0.0004, -0.0237,  0.0566,\n",
      "        -0.0464,  0.0073,  0.0505,  0.0869,  0.0541, -0.0308, -0.0232, -0.0589,\n",
      "         0.0408, -0.0619,  0.0195,  0.0824,  0.0094, -0.0386, -0.0389,  0.0041,\n",
      "         0.0273,  0.0018, -0.0821, -0.0553,  0.0789, -0.0475, -0.0550, -0.0576,\n",
      "         0.0754, -0.0156, -0.0649,  0.0574, -0.0645, -0.0229,  0.0801, -0.0320,\n",
      "        -0.0101,  0.0598,  0.0363,  0.0370, -0.0500,  0.0284,  0.0152, -0.0048,\n",
      "        -0.0858, -0.0382,  0.0140, -0.0010, -0.0077,  0.0266, -0.0192,  0.0754,\n",
      "         0.0371, -0.0240, -0.0605, -0.0204, -0.0252,  0.0775, -0.0712, -0.0454,\n",
      "        -0.0844, -0.0483, -0.0566, -0.0809,  0.0540,  0.0172,  0.0808, -0.0849,\n",
      "         0.0349, -0.0499,  0.0192,  0.0186,  0.0578,  0.0231,  0.0856,  0.0630,\n",
      "         0.0626,  0.0859, -0.0813,  0.0672,  0.0118, -0.0860,  0.0126, -0.0831,\n",
      "         0.0567, -0.0210,  0.0728,  0.0222,  0.0670,  0.0366, -0.0157,  0.0594,\n",
      "         0.0767, -0.0436, -0.0494,  0.0683, -0.0498, -0.0243, -0.0842,  0.0621,\n",
      "        -0.0515,  0.0108,  0.0600,  0.0768,  0.0331, -0.0667, -0.0750,  0.0765,\n",
      "        -0.0507, -0.0246, -0.0452,  0.0444,  0.0450,  0.0593, -0.0328,  0.0553,\n",
      "         0.0279, -0.0503,  0.0682, -0.0568,  0.0723, -0.0527,  0.0169, -0.0392,\n",
      "         0.0861,  0.0673,  0.0708,  0.0117,  0.0738,  0.0096,  0.0780, -0.0621,\n",
      "        -0.0725,  0.0110, -0.0228, -0.0143, -0.0720, -0.0367,  0.0839,  0.0403,\n",
      "        -0.0822, -0.0322,  0.0792,  0.0208, -0.0787, -0.0121,  0.0467, -0.0658,\n",
      "         0.0602, -0.0606, -0.0213, -0.0368,  0.0110, -0.0308,  0.0492, -0.0281,\n",
      "         0.0061,  0.0011,  0.0632, -0.0482,  0.0878, -0.0284,  0.0430, -0.0198,\n",
      "         0.0328,  0.0362,  0.0387, -0.0805,  0.0589,  0.0057, -0.0810, -0.0154,\n",
      "        -0.0117,  0.0535,  0.0154, -0.0289, -0.0271, -0.0339, -0.0547, -0.0052,\n",
      "         0.0713, -0.0420,  0.0104, -0.0234, -0.0089,  0.0267,  0.0037, -0.0666,\n",
      "        -0.0302,  0.0859,  0.0279,  0.0606, -0.0200, -0.0089, -0.0131, -0.0602,\n",
      "         0.0167, -0.0846,  0.0846, -0.0479,  0.0755,  0.0856, -0.0469,  0.0243,\n",
      "        -0.0490, -0.0578, -0.0330, -0.0181,  0.0335, -0.0786,  0.0742, -0.0481,\n",
      "        -0.0263,  0.0834, -0.0402,  0.0062,  0.0589, -0.0003,  0.0452,  0.0683,\n",
      "         0.0871,  0.0225,  0.0347,  0.0232,  0.0872,  0.0465, -0.0344,  0.0149,\n",
      "        -0.0456, -0.0311, -0.0724,  0.0583,  0.0843,  0.0720, -0.0378, -0.0407,\n",
      "         0.0347, -0.0325,  0.0121, -0.0320, -0.0266, -0.0217,  0.0741, -0.0136],\n",
      "       requires_grad=True))\n",
      "('gen_logvar.weight', Parameter containing:\n",
      "tensor([[-0.0552, -0.0432,  0.0274,  ...,  0.0070, -0.0544,  0.0360],\n",
      "        [ 0.0069, -0.0195,  0.0224,  ..., -0.0426,  0.0054, -0.0523],\n",
      "        [-0.0349, -0.0232, -0.0051,  ..., -0.0558, -0.0014,  0.0430],\n",
      "        ...,\n",
      "        [-0.0451,  0.0286,  0.0529,  ...,  0.0316, -0.0557, -0.0571],\n",
      "        [ 0.0405,  0.0467, -0.0329,  ...,  0.0586,  0.0258, -0.0483],\n",
      "        [-0.0131,  0.0158,  0.0468,  ..., -0.0003, -0.0268,  0.0105]],\n",
      "       requires_grad=True))\n",
      "('gen_logvar.bias', Parameter containing:\n",
      "tensor([-0.0122,  0.0617,  0.0330,  ...,  0.0239,  0.0580,  0.0580],\n",
      "       requires_grad=True))\n",
      "('rnn_alpha.weight_ih_l0', Parameter containing:\n",
      "tensor([[ 0.1298,  0.0473, -0.0212,  ..., -0.1091, -0.0463,  0.0653],\n",
      "        [-0.1126, -0.1386,  0.0148,  ..., -0.1197, -0.0263, -0.0623],\n",
      "        [-0.1220, -0.0324,  0.0977,  ..., -0.0426, -0.0011, -0.0578],\n",
      "        ...,\n",
      "        [-0.1289, -0.0734, -0.0759,  ...,  0.1077, -0.0088, -0.0182],\n",
      "        [-0.0039, -0.0200, -0.0215,  ..., -0.0757,  0.0388, -0.0690],\n",
      "        [-0.0802, -0.0507,  0.0136,  ..., -0.0762, -0.0493,  0.0153]],\n",
      "       requires_grad=True))\n",
      "('rnn_alpha.weight_hh_l0', Parameter containing:\n",
      "tensor([[-0.1119, -0.0386, -0.1169,  ...,  0.0698, -0.0497, -0.0248],\n",
      "        [ 0.1185,  0.0499, -0.0925,  ..., -0.0167,  0.1082,  0.0835],\n",
      "        [-0.0648,  0.0790, -0.0392,  ..., -0.0211, -0.0167, -0.1156],\n",
      "        ...,\n",
      "        [ 0.0186, -0.0574,  0.1356,  ...,  0.0734, -0.1352, -0.1381],\n",
      "        [-0.1049,  0.0065, -0.0915,  ...,  0.1126,  0.0747, -0.0553],\n",
      "        [ 0.0649, -0.1389, -0.1223,  ...,  0.0459,  0.0948, -0.0060]],\n",
      "       requires_grad=True))\n",
      "('rnn_alpha.bias_ih_l0', Parameter containing:\n",
      "tensor([ 0.0945,  0.0842, -0.0944,  0.0125, -0.0875,  0.1230, -0.0287, -0.0132,\n",
      "         0.0057, -0.0675, -0.1265, -0.0092, -0.1191,  0.1336, -0.0240, -0.1358,\n",
      "         0.1317, -0.1041, -0.0340,  0.0101,  0.0253, -0.1080,  0.0167,  0.0650,\n",
      "        -0.0448, -0.0882, -0.0149,  0.0691,  0.0063, -0.1177,  0.0264,  0.0727,\n",
      "         0.1411,  0.0707, -0.0829,  0.1285,  0.1261,  0.0773, -0.1197,  0.0425,\n",
      "         0.0340,  0.1276,  0.0248, -0.0547, -0.0005,  0.1187,  0.1240, -0.0162,\n",
      "        -0.0447, -0.1033,  0.1009,  0.0373,  0.1404,  0.1212,  0.0111,  0.0910,\n",
      "         0.0120, -0.0844, -0.0356,  0.0231,  0.0230,  0.0381,  0.1406,  0.0707,\n",
      "         0.0311,  0.0677,  0.0156,  0.0941,  0.0699, -0.0425,  0.1343, -0.1371,\n",
      "         0.0333,  0.0008,  0.1173,  0.0897, -0.0031, -0.1180, -0.0378, -0.1155,\n",
      "        -0.0705, -0.0508, -0.0459, -0.0839, -0.1179,  0.0863,  0.0150, -0.1280,\n",
      "        -0.0399, -0.0338,  0.1254,  0.1096,  0.0781,  0.0038,  0.1073,  0.1399,\n",
      "         0.0921,  0.1389,  0.0260, -0.1212, -0.0181, -0.0776,  0.1018, -0.0983,\n",
      "        -0.0342,  0.1379, -0.0211, -0.0286, -0.0821,  0.0543,  0.0405, -0.1296,\n",
      "         0.0158, -0.0444, -0.0102, -0.0497, -0.0003,  0.0973, -0.0570, -0.0184,\n",
      "        -0.1057, -0.0989,  0.0262, -0.1398, -0.1313,  0.0930,  0.0876,  0.1399,\n",
      "        -0.0128, -0.1218, -0.1021, -0.0290,  0.1082, -0.0631, -0.0503, -0.1305,\n",
      "         0.0644, -0.0596,  0.0082,  0.0768,  0.1197,  0.0878,  0.0341,  0.0404,\n",
      "        -0.0125, -0.0436,  0.1131, -0.0708,  0.0705,  0.0361,  0.0419, -0.1180,\n",
      "         0.0222,  0.0605, -0.1346,  0.0350,  0.0478, -0.0892, -0.0781, -0.0433,\n",
      "        -0.0530,  0.0701,  0.1395, -0.0681,  0.1029, -0.0760, -0.1280, -0.0525,\n",
      "        -0.0542,  0.0780,  0.0851, -0.1123,  0.0312, -0.1007,  0.1120, -0.1092,\n",
      "        -0.0004,  0.0147, -0.0262, -0.0829,  0.1243,  0.1402, -0.0045, -0.1149,\n",
      "         0.0474,  0.0089,  0.0113, -0.0139,  0.0615, -0.0134,  0.0581, -0.1286,\n",
      "        -0.0598, -0.0960, -0.0389, -0.1037, -0.0066,  0.1098,  0.0338,  0.1046],\n",
      "       requires_grad=True))\n",
      "('rnn_alpha.bias_hh_l0', Parameter containing:\n",
      "tensor([-0.0178, -0.0966, -0.0457,  0.0674, -0.1302, -0.0010, -0.0237,  0.0819,\n",
      "        -0.0803,  0.1144,  0.1336,  0.0098, -0.0824, -0.1235,  0.1206,  0.1106,\n",
      "        -0.1000,  0.0122, -0.0316,  0.0415,  0.1071, -0.0797, -0.0139, -0.0628,\n",
      "         0.1050, -0.0206,  0.0364,  0.1097, -0.0302,  0.0589, -0.1139,  0.0217,\n",
      "        -0.0170, -0.1250,  0.0216,  0.0907, -0.1285, -0.0593,  0.0141, -0.0019,\n",
      "        -0.1404,  0.0349, -0.0539,  0.0043, -0.1361,  0.1301, -0.1225,  0.0477,\n",
      "         0.1380,  0.0842,  0.0834,  0.0306,  0.0258,  0.0081,  0.0641, -0.0696,\n",
      "        -0.0017, -0.0159,  0.0947,  0.0600, -0.1330,  0.0698, -0.0369,  0.1094,\n",
      "         0.1411, -0.1354, -0.0424, -0.0852, -0.0366,  0.0561,  0.1100, -0.0967,\n",
      "        -0.1287, -0.0044,  0.0337,  0.0043,  0.1192,  0.1215, -0.1368, -0.0814,\n",
      "         0.1232, -0.0876, -0.0647,  0.0674,  0.1199, -0.0848, -0.0562, -0.0026,\n",
      "         0.0688,  0.0208, -0.1011,  0.0689, -0.0268,  0.0048,  0.0387, -0.0434,\n",
      "         0.0070,  0.1016, -0.0454,  0.1129,  0.1083, -0.1338,  0.1177, -0.0437,\n",
      "         0.1371,  0.0096, -0.1245, -0.0496,  0.0470, -0.0376, -0.0657, -0.0735,\n",
      "         0.0981,  0.1307, -0.0220, -0.0747,  0.0102, -0.0497, -0.0603,  0.1131,\n",
      "        -0.0667, -0.0963,  0.0974,  0.0584, -0.0568,  0.1010, -0.0859,  0.0932,\n",
      "        -0.0089,  0.1188,  0.1283,  0.0158,  0.1222, -0.0440,  0.0820, -0.0192,\n",
      "         0.0486,  0.0933, -0.1283, -0.0764, -0.0671, -0.0245,  0.0632, -0.1400,\n",
      "        -0.0831,  0.0812,  0.1324,  0.0214,  0.1023,  0.1335,  0.0304,  0.1240,\n",
      "        -0.0634,  0.0969,  0.1317, -0.0028, -0.0786,  0.0824,  0.0576, -0.0076,\n",
      "         0.0359, -0.0732, -0.0152,  0.0750, -0.0618, -0.0569,  0.1393, -0.0635,\n",
      "        -0.0952,  0.0709, -0.0384, -0.0099, -0.1268,  0.0977, -0.1045, -0.0316,\n",
      "        -0.0142, -0.1385,  0.1238,  0.0061,  0.0461, -0.0347,  0.0823, -0.1120,\n",
      "         0.1000,  0.0109,  0.1229,  0.0177, -0.0960,  0.0649, -0.0728,  0.1051,\n",
      "         0.1298, -0.0727, -0.0169,  0.1227,  0.0550, -0.1323,  0.0685,  0.0088],\n",
      "       requires_grad=True))\n",
      "('mlp_alpha.0.weight', Parameter containing:\n",
      "tensor([[-1.5096e-02,  3.8942e-02,  1.1996e-01, -4.3051e-02, -3.5921e-02,\n",
      "         -5.2717e-02,  1.1877e-01,  7.6026e-02, -9.1969e-02,  1.0691e-01,\n",
      "          9.5549e-02, -1.0891e-01,  9.4937e-02, -9.1600e-02,  6.2107e-02,\n",
      "          1.3409e-01,  1.6384e-02, -2.2642e-02, -1.2923e-01,  8.9156e-02,\n",
      "          5.1795e-02, -1.1167e-01, -1.0967e-01, -1.4281e-02,  8.2551e-02,\n",
      "          4.4773e-02, -3.3578e-02, -9.6759e-02,  1.0173e-01, -1.3581e-01,\n",
      "         -5.6971e-02,  1.9351e-02, -1.4027e-01,  5.6918e-02,  2.5595e-02,\n",
      "          1.6798e-02, -1.3687e-01, -5.7726e-02,  3.4472e-02, -3.1964e-02,\n",
      "         -7.6002e-02,  9.9295e-02, -1.3487e-01, -1.3120e-01,  1.3909e-01,\n",
      "         -3.7308e-02,  7.6896e-02,  1.9855e-02,  4.4391e-02, -3.8832e-02],\n",
      "        [ 1.9909e-02, -9.5589e-02,  1.5404e-02, -5.0524e-02,  6.0282e-03,\n",
      "          1.1982e-01,  4.1383e-02, -5.1543e-02,  5.5518e-02,  1.1177e-01,\n",
      "          9.9739e-02,  3.7872e-02, -2.2375e-02, -1.1341e-01, -3.7700e-05,\n",
      "         -1.0646e-02, -9.8041e-02,  4.7341e-05, -1.2574e-01, -2.2583e-02,\n",
      "          1.2467e-01, -8.3427e-02,  3.6365e-02, -5.0563e-02,  1.0214e-01,\n",
      "          2.4438e-02, -7.8982e-02,  4.5344e-02, -1.0896e-01, -4.4115e-02,\n",
      "         -1.6567e-02, -8.3477e-02,  1.1200e-01,  1.0598e-01, -8.0898e-02,\n",
      "          4.0244e-02, -1.2007e-01, -3.7143e-02, -3.1122e-02,  9.6741e-02,\n",
      "         -1.2825e-02,  9.5141e-03,  5.6369e-02,  3.3942e-02, -7.6275e-02,\n",
      "         -1.0521e-01,  1.3984e-01,  1.3352e-01, -1.0705e-01,  3.2846e-02],\n",
      "        [-5.3190e-02, -1.2875e-01,  4.9962e-02,  7.8858e-02, -7.4634e-02,\n",
      "         -1.3194e-01, -5.8225e-02, -1.1557e-01, -8.8485e-02, -1.0851e-02,\n",
      "         -9.1212e-02, -1.2834e-01, -6.9013e-02,  8.1804e-02,  3.7631e-02,\n",
      "          8.3375e-02, -1.3045e-01,  1.1503e-01,  7.4146e-02,  4.2482e-03,\n",
      "         -1.2693e-01, -9.0854e-02, -2.4794e-02, -1.1210e-01,  4.8431e-02,\n",
      "         -3.1252e-02,  2.1674e-02, -1.2334e-01,  7.1907e-02, -6.7431e-02,\n",
      "          1.8105e-02,  1.8682e-02,  2.8485e-02,  7.8184e-02, -3.6599e-03,\n",
      "          1.5786e-02, -7.5295e-02, -1.2523e-01,  8.4005e-03, -5.2858e-03,\n",
      "         -1.3466e-01,  1.1026e-01,  8.5854e-02, -2.6441e-02,  6.9202e-02,\n",
      "         -1.2903e-01,  6.0271e-02, -3.5691e-03, -9.0705e-02, -6.2484e-02],\n",
      "        [ 9.9769e-02, -2.4940e-02,  8.7834e-02, -8.8947e-02, -1.1431e-01,\n",
      "          2.9329e-02,  1.6949e-02,  5.1559e-02,  1.2532e-01, -9.2350e-02,\n",
      "          7.1810e-02, -4.7828e-02, -5.8375e-02,  1.2169e-01,  1.2537e-01,\n",
      "          8.8284e-02, -8.5951e-02, -1.2842e-01,  1.0817e-01,  4.7931e-02,\n",
      "         -5.7993e-03, -7.5779e-02,  1.2904e-01, -1.2000e-02, -7.1949e-02,\n",
      "         -8.2180e-02,  6.9454e-02, -3.4080e-02,  5.8200e-02,  8.3403e-02,\n",
      "          7.5347e-02, -5.8165e-02,  2.2885e-02, -9.6368e-03,  1.4093e-01,\n",
      "          4.0799e-02, -5.1004e-02, -2.1248e-02,  3.4434e-02, -1.2699e-01,\n",
      "          2.7344e-02, -2.3666e-03,  2.5383e-02,  1.3425e-01,  2.7847e-03,\n",
      "          3.4757e-02,  1.3006e-01, -2.6105e-02,  3.0066e-02,  1.0537e-01],\n",
      "        [-3.7066e-02,  2.6475e-02,  4.0379e-02, -4.2531e-02, -6.6420e-02,\n",
      "         -1.1347e-01,  1.3463e-01,  9.5391e-02, -1.3847e-01,  2.0054e-02,\n",
      "         -1.4777e-03, -9.7726e-02,  2.3113e-02,  1.0668e-01, -1.3187e-01,\n",
      "          1.0236e-01, -2.4481e-02, -2.1021e-02,  4.3647e-02, -1.0732e-01,\n",
      "          1.1884e-02, -1.1330e-02, -6.7249e-02,  7.2569e-02, -7.8661e-02,\n",
      "         -9.8311e-02,  6.9855e-02,  1.0089e-01, -9.4036e-02,  9.4918e-02,\n",
      "          1.1624e-01, -1.5278e-02,  1.0164e-01, -6.8840e-02,  9.4352e-02,\n",
      "          2.4683e-02,  2.0152e-02, -1.2198e-01,  6.2795e-03,  9.0129e-02,\n",
      "          9.7381e-02, -4.0610e-02,  9.3557e-02,  1.1788e-01,  1.2501e-01,\n",
      "         -1.3968e-01, -7.1404e-02,  1.0293e-02, -3.0679e-02, -4.2653e-02],\n",
      "        [-1.5817e-02, -6.2192e-02, -1.0145e-01, -3.8976e-02, -5.7742e-03,\n",
      "          3.0742e-02, -2.1765e-02,  3.5247e-02, -7.5735e-02,  1.4048e-01,\n",
      "          4.0742e-02, -1.0266e-01, -1.0842e-01,  3.4026e-03,  1.1055e-01,\n",
      "          1.1694e-02,  5.9557e-02, -6.3155e-02, -1.1678e-01, -8.5157e-02,\n",
      "          2.7107e-02,  1.4476e-02, -7.5338e-03, -4.1832e-02,  7.8546e-02,\n",
      "          4.5386e-02, -3.2408e-02, -8.1278e-02,  1.1873e-02, -2.6366e-02,\n",
      "         -9.7202e-04,  1.1624e-01,  2.4092e-02,  2.7310e-02, -8.6574e-02,\n",
      "          7.6022e-02, -1.0083e-01, -7.5097e-03, -2.8283e-02,  8.5060e-02,\n",
      "          7.6548e-02, -8.8661e-02, -4.0863e-02, -8.4879e-02,  2.5933e-02,\n",
      "          1.1195e-01,  1.7539e-02, -1.3755e-01, -5.6812e-02, -1.1189e-01],\n",
      "        [-6.3228e-02,  1.3378e-01, -2.4655e-02,  1.3099e-01,  1.4016e-01,\n",
      "         -9.2547e-02,  2.9667e-02,  1.3793e-01,  4.1586e-02,  1.3330e-01,\n",
      "          7.0093e-02, -6.9479e-02,  4.4372e-02, -7.0308e-02,  8.7772e-02,\n",
      "         -4.9173e-02, -3.8148e-02,  4.3138e-03, -7.0162e-02,  4.0386e-02,\n",
      "         -1.2920e-01,  1.3292e-01, -5.6113e-02,  7.4284e-02, -3.2953e-02,\n",
      "          1.3800e-02, -2.7170e-02, -1.1649e-01,  1.2489e-01,  1.4773e-02,\n",
      "         -1.3418e-01,  5.5621e-02,  6.6147e-02, -1.3189e-01,  7.6329e-02,\n",
      "         -1.0819e-01,  3.0917e-03,  9.7234e-02, -1.2664e-01,  1.3528e-01,\n",
      "         -3.7111e-02,  7.5261e-02, -7.7440e-02, -9.8050e-05,  4.1647e-02,\n",
      "         -5.5123e-02,  1.1601e-01, -7.0725e-02, -1.1484e-01, -5.0674e-02],\n",
      "        [-4.1646e-02,  9.8332e-02, -1.4132e-01,  1.0698e-01,  6.3132e-02,\n",
      "         -4.0633e-02, -9.8098e-02,  1.0960e-01, -4.6639e-02, -8.6058e-02,\n",
      "          7.7763e-02, -9.9319e-02, -3.8060e-02,  3.6024e-02, -1.3650e-01,\n",
      "         -8.9670e-02,  6.0045e-02,  9.9251e-02,  6.2819e-02,  4.6697e-02,\n",
      "         -1.4101e-01, -1.4068e-01,  8.7042e-02,  7.3395e-02, -3.3832e-02,\n",
      "         -7.1626e-02, -6.5041e-02,  1.1227e-01, -6.3517e-02,  7.3900e-02,\n",
      "         -7.3685e-02,  2.6637e-02,  8.2278e-02,  4.4234e-03,  1.1057e-01,\n",
      "          1.1556e-02, -9.5904e-02,  6.8219e-02, -4.3474e-02,  1.0727e-01,\n",
      "         -2.4719e-02,  8.6927e-02, -4.6305e-02, -1.3554e-02,  7.1450e-02,\n",
      "         -1.3966e-01, -5.1309e-02,  9.8076e-02,  1.1051e-01, -1.0029e-01],\n",
      "        [-5.3362e-02,  3.9846e-02,  9.6770e-02, -7.5912e-02,  1.3474e-01,\n",
      "          3.2001e-02,  3.3644e-02,  1.3683e-02,  1.0557e-01,  9.5489e-02,\n",
      "         -1.0156e-03, -5.1295e-02, -2.9506e-04, -6.3518e-02,  1.9762e-02,\n",
      "          4.1606e-02, -9.2647e-02, -7.6752e-02, -9.6450e-02, -7.5003e-02,\n",
      "          7.4682e-03, -3.3438e-02,  1.1376e-01,  1.4030e-01,  3.9007e-02,\n",
      "          4.4649e-02,  7.7062e-02,  2.7281e-02, -1.0144e-02, -1.3480e-01,\n",
      "          1.1720e-01, -3.9147e-02, -9.0311e-02, -1.1070e-01, -6.9660e-02,\n",
      "          1.9444e-02,  7.4209e-02,  3.6189e-03,  1.5173e-02, -7.8825e-02,\n",
      "          2.9271e-02, -1.0499e-01, -6.9012e-02, -9.2735e-02,  9.2957e-02,\n",
      "          9.9947e-02, -5.8694e-02, -6.2481e-02, -1.0506e-01,  1.3111e-01],\n",
      "        [ 1.4091e-01, -3.7008e-02,  4.1737e-02, -1.3043e-01,  1.1382e-01,\n",
      "         -9.1261e-02, -1.3385e-01, -1.3449e-01, -9.0722e-02, -6.2312e-03,\n",
      "         -1.2721e-01,  1.1981e-02,  6.3944e-02,  1.4982e-02,  1.1632e-01,\n",
      "          5.1637e-02,  1.2756e-01, -1.2452e-01,  1.0394e-01,  7.0577e-02,\n",
      "         -8.6574e-02,  5.3060e-02,  9.4109e-02,  1.3313e-01, -9.0807e-02,\n",
      "         -6.8072e-02,  1.1445e-01,  1.1721e-01, -1.3811e-01, -7.8765e-02,\n",
      "         -9.8116e-02,  7.6437e-02,  4.4341e-02,  1.9682e-02, -7.3098e-02,\n",
      "          4.7339e-02, -6.4141e-02, -2.3729e-02,  2.4511e-02, -4.7908e-02,\n",
      "          1.1692e-01,  5.0353e-02, -1.3720e-01, -1.3609e-01, -3.0761e-02,\n",
      "         -1.9990e-02, -2.4095e-03, -4.3124e-02,  1.3508e-01, -1.2735e-01]],\n",
      "       requires_grad=True))\n",
      "('mlp_alpha.0.bias', Parameter containing:\n",
      "tensor([ 0.1168, -0.1094,  0.0986,  0.1337,  0.0434,  0.1053, -0.0398,  0.1386,\n",
      "        -0.0657, -0.1407], requires_grad=True))\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "kvae = KVAE(model=model,\r\n",
    "            lr = 3e-3,#3e-6,\r\n",
    "            lr_tot = 1e-3,#1e-6,\r\n",
    "            epochs = 10,\r\n",
    "            batch_size = batch_size,\r\n",
    "            early_stop_patience = 20,\r\n",
    "            save_frequency = 10,\r\n",
    "            only_vae_epochs = 3,\r\n",
    "            kf_update_epochs = 2,\r\n",
    "            save_dir = \"results\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# TODO: difference between forward and forward_vae?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "kvae.train(train_dataloader, val_dataloader)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('A', Parameter containing:\n",
      "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]]], requires_grad=True))\n",
      "('B', Parameter containing:\n",
      "tensor([[[-0.0415,  0.0224, -0.0845,  ...,  0.0782,  0.0017, -0.0261],\n",
      "         [ 0.0448,  0.0482,  0.0582,  ...,  0.0023, -0.0178,  0.0040],\n",
      "         [-0.0344,  0.0230,  0.0470,  ...,  0.0524, -0.0240, -0.0124],\n",
      "         ...,\n",
      "         [-0.1365,  0.0423, -0.0067,  ..., -0.0846, -0.1148, -0.0437],\n",
      "         [ 0.0127,  0.1037, -0.0036,  ..., -0.0651, -0.0315, -0.0013],\n",
      "         [-0.0357, -0.0112, -0.0251,  ..., -0.0245, -0.0426,  0.0317]],\n",
      "\n",
      "        [[ 0.0451,  0.0728, -0.0756,  ...,  0.0745,  0.0767, -0.0455],\n",
      "         [ 0.0628, -0.0542, -0.0276,  ...,  0.0816,  0.0542, -0.0259],\n",
      "         [ 0.0224, -0.0193,  0.0573,  ...,  0.0230,  0.0109, -0.0259],\n",
      "         ...,\n",
      "         [-0.0157, -0.0673,  0.0323,  ..., -0.0025,  0.0192,  0.0352],\n",
      "         [-0.0511,  0.0560, -0.0357,  ..., -0.0063,  0.1517, -0.0110],\n",
      "         [-0.0508,  0.0364,  0.1193,  ..., -0.0149, -0.0099, -0.0681]],\n",
      "\n",
      "        [[ 0.0572,  0.0572, -0.0646,  ..., -0.0298,  0.0217,  0.0255],\n",
      "         [-0.0580, -0.0165,  0.0255,  ...,  0.0477, -0.0126, -0.0412],\n",
      "         [ 0.0690,  0.0307,  0.0078,  ...,  0.0321, -0.0017,  0.0231],\n",
      "         ...,\n",
      "         [-0.0482,  0.0328,  0.0216,  ..., -0.0481,  0.0435,  0.0034],\n",
      "         [ 0.0344,  0.0099,  0.0525,  ..., -0.0151, -0.0336, -0.0732],\n",
      "         [-0.0652, -0.0422, -0.0594,  ..., -0.0757,  0.0286, -0.0666]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0286,  0.0523,  0.0295,  ...,  0.0582,  0.1348, -0.0072],\n",
      "         [-0.0615,  0.0374,  0.0137,  ..., -0.0765, -0.0837, -0.0931],\n",
      "         [ 0.0389, -0.0467, -0.0503,  ..., -0.1021,  0.0025,  0.0882],\n",
      "         ...,\n",
      "         [-0.0859,  0.0695, -0.0237,  ...,  0.0318, -0.0591,  0.0434],\n",
      "         [-0.0450, -0.0144, -0.0258,  ..., -0.0660,  0.0051, -0.0945],\n",
      "         [ 0.0686, -0.0623, -0.0479,  ...,  0.0452,  0.0321,  0.1110]],\n",
      "\n",
      "        [[-0.0469, -0.0082,  0.0445,  ...,  0.1085, -0.0110, -0.0390],\n",
      "         [-0.1450, -0.0910,  0.0548,  ..., -0.0281, -0.0161, -0.0421],\n",
      "         [ 0.0453, -0.0595,  0.0115,  ..., -0.0526,  0.0629,  0.0004],\n",
      "         ...,\n",
      "         [ 0.1150,  0.0034, -0.0681,  ...,  0.0027, -0.0237,  0.0097],\n",
      "         [-0.0631,  0.0269, -0.0140,  ...,  0.1301,  0.0137, -0.0165],\n",
      "         [ 0.0445, -0.0357, -0.0076,  ..., -0.0692, -0.0044,  0.0381]],\n",
      "\n",
      "        [[ 0.0266, -0.0174, -0.0156,  ...,  0.0240,  0.0016,  0.0272],\n",
      "         [-0.0196, -0.0248, -0.0323,  ...,  0.0556, -0.0854,  0.0498],\n",
      "         [ 0.0006, -0.0419, -0.0026,  ..., -0.0289, -0.0417, -0.0134],\n",
      "         ...,\n",
      "         [-0.0527,  0.0110,  0.0755,  ...,  0.0005, -0.0615, -0.0204],\n",
      "         [ 0.0128, -0.0399,  0.0293,  ...,  0.0418, -0.1086,  0.0860],\n",
      "         [-0.0282, -0.0010,  0.0112,  ...,  0.0411,  0.0183, -0.0209]]],\n",
      "       requires_grad=True))\n",
      "('C', Parameter containing:\n",
      "tensor([[[ 0.0881,  0.0916,  0.0322,  ...,  0.0289, -0.1018,  0.0352],\n",
      "         [-0.1072, -0.0337,  0.0086,  ..., -0.0677,  0.1188, -0.0234],\n",
      "         [ 0.0265, -0.0767,  0.0469,  ..., -0.0792, -0.0133, -0.0373],\n",
      "         ...,\n",
      "         [ 0.1424, -0.0245,  0.0403,  ..., -0.0467,  0.0112,  0.0982],\n",
      "         [-0.0232, -0.0373, -0.0655,  ...,  0.0099,  0.0245, -0.0322],\n",
      "         [-0.0736, -0.0407,  0.0590,  ...,  0.0193,  0.0022, -0.0172]],\n",
      "\n",
      "        [[ 0.0312,  0.0022, -0.0321,  ..., -0.0947, -0.0413, -0.0248],\n",
      "         [-0.0105, -0.0003,  0.0441,  ...,  0.0194,  0.0571, -0.0439],\n",
      "         [-0.0258,  0.0219, -0.0533,  ..., -0.0737, -0.0245,  0.0081],\n",
      "         ...,\n",
      "         [-0.0408,  0.0712,  0.0388,  ..., -0.1037,  0.0129,  0.0252],\n",
      "         [-0.0359, -0.1218,  0.0428,  ...,  0.0737,  0.0448,  0.0279],\n",
      "         [ 0.0074, -0.0078,  0.0146,  ..., -0.0117,  0.0153, -0.0376]],\n",
      "\n",
      "        [[-0.0303, -0.0114,  0.0068,  ..., -0.0581,  0.0276,  0.0727],\n",
      "         [ 0.0187, -0.0961,  0.0015,  ..., -0.0263, -0.1127,  0.1268],\n",
      "         [-0.0170, -0.0546, -0.0344,  ..., -0.0218, -0.0344,  0.0802],\n",
      "         ...,\n",
      "         [ 0.0315, -0.0225,  0.0406,  ...,  0.0136,  0.0260,  0.0338],\n",
      "         [ 0.0135, -0.0054, -0.0247,  ...,  0.0231,  0.0035,  0.0097],\n",
      "         [ 0.0050, -0.0427, -0.0951,  ...,  0.0586,  0.0643, -0.0147]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0171,  0.0848,  0.0625,  ..., -0.0186, -0.0597, -0.0279],\n",
      "         [-0.0102,  0.0854,  0.0539,  ...,  0.0685, -0.0247, -0.0272],\n",
      "         [-0.0474, -0.1281, -0.0006,  ...,  0.0441, -0.0144, -0.0197],\n",
      "         ...,\n",
      "         [-0.0741,  0.0899,  0.0918,  ..., -0.0025, -0.0201, -0.0204],\n",
      "         [-0.0254,  0.0247,  0.0809,  ...,  0.0103, -0.0163,  0.0439],\n",
      "         [ 0.0015,  0.0603,  0.0191,  ..., -0.0172, -0.0170,  0.0425]],\n",
      "\n",
      "        [[ 0.0322, -0.0258,  0.0245,  ...,  0.1261,  0.0714, -0.0080],\n",
      "         [-0.0306,  0.0866, -0.0623,  ..., -0.0432,  0.0023,  0.0171],\n",
      "         [-0.0371, -0.0480,  0.0339,  ..., -0.0051, -0.0595, -0.0424],\n",
      "         ...,\n",
      "         [ 0.0348,  0.0496, -0.0234,  ..., -0.0767, -0.0516, -0.0261],\n",
      "         [ 0.0632,  0.0279,  0.0137,  ...,  0.0382,  0.1194,  0.0008],\n",
      "         [ 0.0315, -0.0745,  0.0936,  ...,  0.0252, -0.0686, -0.1001]],\n",
      "\n",
      "        [[ 0.0017,  0.0314,  0.0105,  ..., -0.0344,  0.0729, -0.0237],\n",
      "         [-0.0284,  0.0658, -0.0031,  ...,  0.0177, -0.0097, -0.0084],\n",
      "         [-0.0323,  0.0557,  0.0115,  ...,  0.0399,  0.0608,  0.0841],\n",
      "         ...,\n",
      "         [ 0.0110, -0.0608, -0.0316,  ..., -0.0588,  0.0283,  0.0648],\n",
      "         [ 0.0228,  0.0037, -0.0172,  ...,  0.0315,  0.0499,  0.0548],\n",
      "         [-0.0747,  0.0477, -0.0456,  ...,  0.0103,  0.0171, -0.0421]]],\n",
      "       requires_grad=True))\n",
      "('a_init', Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True))\n",
      "('mlp_x_a.linear0.weight', Parameter containing:\n",
      "tensor([[-0.0249, -0.0215,  0.0142,  ..., -0.0251,  0.0297, -0.0165],\n",
      "        [ 0.0201, -0.0260,  0.0123,  ..., -0.0140,  0.0118,  0.0081],\n",
      "        [-0.0270,  0.0273, -0.0297,  ..., -0.0293,  0.0302, -0.0155],\n",
      "        ...,\n",
      "        [ 0.0204,  0.0023,  0.0075,  ...,  0.0124,  0.0073,  0.0244],\n",
      "        [ 0.0061, -0.0137, -0.0087,  ..., -0.0107,  0.0092,  0.0068],\n",
      "        [-0.0030,  0.0065,  0.0171,  ..., -0.0130,  0.0239, -0.0034]],\n",
      "       requires_grad=True))\n",
      "('mlp_x_a.linear0.bias', Parameter containing:\n",
      "tensor([-2.7785e-02, -1.1607e-02,  1.9325e-02,  2.3163e-02, -2.3249e-02,\n",
      "         3.9503e-03,  1.5089e-02,  2.5937e-02,  2.5748e-02,  5.2227e-03,\n",
      "        -1.8925e-02, -9.8596e-03, -1.3348e-02, -1.8351e-02,  2.7838e-02,\n",
      "         9.7984e-03, -9.3896e-05,  1.3849e-02, -2.0284e-03,  2.2936e-02,\n",
      "         2.8458e-02, -1.7013e-02,  2.7022e-02, -2.3964e-02,  2.5436e-02,\n",
      "         7.7554e-03, -3.5227e-03, -1.4612e-02, -1.9886e-02,  9.4494e-03,\n",
      "         3.0842e-02,  2.3671e-03, -1.5589e-03, -2.7497e-02, -9.6030e-03,\n",
      "        -2.8380e-02, -2.9557e-02, -1.5424e-02, -2.8778e-02, -1.9701e-03,\n",
      "        -1.3097e-02,  1.6123e-02, -1.7350e-02,  7.9105e-03, -2.0306e-02,\n",
      "         2.8410e-02, -5.2765e-03,  6.8417e-03, -1.3147e-02,  1.5514e-02,\n",
      "        -6.4637e-03, -2.9999e-02, -2.1387e-02,  7.1709e-03, -9.0494e-03,\n",
      "        -5.4551e-03, -1.9997e-02,  2.2492e-02,  1.9272e-03,  1.4245e-02,\n",
      "        -2.5356e-03, -2.5007e-02,  2.1073e-02, -6.9278e-03, -5.4802e-03,\n",
      "        -3.4005e-03, -1.9140e-02,  1.4811e-03, -2.6843e-02, -3.0267e-02,\n",
      "        -2.1092e-02,  2.8349e-02,  1.0734e-02, -2.9027e-02, -6.9663e-03,\n",
      "         2.9366e-02, -2.9666e-02,  1.3080e-02,  1.0087e-02, -1.9830e-02,\n",
      "        -6.3985e-03,  1.7222e-02,  1.4453e-02,  1.6646e-02,  1.2086e-03,\n",
      "         1.7829e-02, -1.0510e-02, -3.0286e-02, -2.2111e-02,  2.7798e-02,\n",
      "        -3.1938e-03,  1.2441e-03, -7.7710e-03, -2.6242e-02, -2.8625e-02,\n",
      "         2.0771e-02,  2.7159e-02,  7.9647e-03, -1.7642e-02,  1.7107e-02,\n",
      "        -2.8478e-02,  2.8644e-02, -2.3848e-02,  1.5027e-02,  1.0715e-02,\n",
      "         1.7725e-02, -2.5899e-02, -1.7996e-02,  3.6985e-04, -2.9884e-02,\n",
      "        -2.0710e-02,  2.5384e-02, -6.1676e-03,  6.6298e-03, -1.8412e-02,\n",
      "        -8.1926e-03, -2.8112e-02,  1.9692e-02,  3.1305e-03, -6.3202e-03,\n",
      "        -2.4494e-02, -3.2621e-03,  1.2510e-02, -2.0857e-02, -1.2340e-02,\n",
      "        -2.1843e-02, -2.6268e-02, -2.4682e-02, -1.5971e-03, -2.6219e-02,\n",
      "        -2.1536e-02,  1.7379e-03,  2.7058e-02,  1.7859e-02,  2.5415e-02,\n",
      "         2.0328e-02, -1.0016e-02, -1.0495e-02,  1.2116e-02,  1.9382e-02,\n",
      "        -2.7955e-02, -2.7847e-02, -1.1735e-02,  2.0493e-02,  3.0282e-02,\n",
      "         3.0453e-02,  1.3018e-02, -2.3624e-03, -2.8994e-03,  6.6342e-03,\n",
      "        -1.2098e-02,  9.4959e-03, -1.2600e-02, -2.2367e-02,  1.6952e-02,\n",
      "         7.3079e-04, -2.7169e-02,  2.0190e-02,  1.3008e-02,  1.9893e-02,\n",
      "         1.3758e-02, -2.2684e-02,  2.7468e-02, -1.6350e-02, -1.8594e-02,\n",
      "        -6.6003e-03, -5.3363e-03, -1.5313e-02,  1.6934e-02, -2.9975e-02,\n",
      "         2.5900e-04,  1.3911e-02,  1.7128e-02, -3.1070e-02, -1.8764e-02,\n",
      "         2.5939e-02,  1.4124e-04,  1.3655e-02,  4.0119e-03,  2.3453e-02,\n",
      "        -2.7919e-02,  1.6296e-02,  1.2945e-03, -1.7393e-02, -3.0923e-02,\n",
      "         2.6052e-02,  1.1935e-02, -1.2385e-02, -2.3672e-02,  1.7005e-02,\n",
      "        -2.7299e-02,  2.6881e-02, -9.1830e-03, -2.2465e-02,  1.6967e-02,\n",
      "        -2.6676e-02, -8.5564e-03, -9.3923e-03, -1.0479e-02, -1.2131e-02,\n",
      "        -1.8917e-02, -2.1974e-02,  1.6140e-02, -1.4637e-02,  1.6005e-02,\n",
      "         1.5625e-02,  1.2281e-03, -2.5233e-02,  2.2431e-02, -1.8698e-02,\n",
      "        -2.7153e-02,  1.4105e-02, -1.0994e-02,  2.4412e-02,  7.8929e-03,\n",
      "         2.4304e-02, -1.5759e-02,  1.1687e-02, -5.4702e-03,  2.0884e-02,\n",
      "         2.5802e-02,  6.6984e-03,  2.2902e-02,  6.9838e-03, -2.2461e-02,\n",
      "        -1.1773e-02,  1.5278e-02,  2.7645e-02, -2.9560e-02, -9.2023e-03,\n",
      "         2.6410e-02,  2.0607e-03, -1.0424e-02,  1.1209e-02, -2.6850e-02,\n",
      "         6.5620e-03,  2.7838e-03,  2.9581e-02, -1.9911e-02, -2.4670e-02,\n",
      "        -2.8638e-02, -1.6163e-03, -1.3993e-02,  2.7619e-02, -2.2779e-02,\n",
      "        -9.5958e-03, -1.4949e-02, -1.2452e-02, -2.3518e-02, -2.3611e-02,\n",
      "         2.1671e-02, -1.4090e-02,  8.8032e-03, -3.3044e-03, -1.0584e-02,\n",
      "         3.0056e-03], requires_grad=True))\n",
      "('mlp_x_a.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.0376,  0.0362,  0.0080,  ...,  0.0162,  0.0306,  0.0317],\n",
      "        [ 0.0149,  0.0158, -0.0621,  ..., -0.0409,  0.0008,  0.0490],\n",
      "        [-0.0536,  0.0216, -0.0405,  ..., -0.0303,  0.0098, -0.0176],\n",
      "        ...,\n",
      "        [ 0.0136,  0.0592,  0.0071,  ..., -0.0010, -0.0366,  0.0103],\n",
      "        [-0.0282,  0.0090,  0.0177,  ..., -0.0017,  0.0391, -0.0064],\n",
      "        [-0.0560,  0.0600, -0.0470,  ..., -0.0172, -0.0403, -0.0609]],\n",
      "       requires_grad=True))\n",
      "('mlp_x_a.linear1.bias', Parameter containing:\n",
      "tensor([ 6.1588e-03,  7.6027e-03,  1.0335e-02, -1.2657e-02, -3.5781e-04,\n",
      "        -4.1597e-02, -4.4844e-02, -2.5220e-02,  4.7021e-02, -5.1997e-02,\n",
      "        -2.3589e-02,  1.4332e-02, -4.6052e-02, -3.4518e-02, -5.9643e-02,\n",
      "        -1.1527e-02, -3.1521e-02, -4.3277e-02, -6.2360e-02,  3.7642e-02,\n",
      "         5.8670e-02,  3.0091e-03,  7.1689e-03,  1.3024e-02,  2.2827e-02,\n",
      "        -9.2975e-03,  6.7557e-04,  1.2831e-02,  3.5236e-03,  1.9765e-02,\n",
      "         5.0273e-02,  1.5904e-02,  7.0610e-03,  3.2591e-02, -4.2952e-02,\n",
      "         4.5517e-03, -4.2402e-02,  4.8162e-02, -5.5996e-02, -1.8728e-02,\n",
      "         4.5756e-03, -1.9393e-03, -5.5820e-02, -1.0983e-02, -4.3220e-02,\n",
      "        -4.1825e-02, -3.9630e-02,  2.0398e-02, -3.7560e-02,  3.9087e-02,\n",
      "         3.9024e-02, -2.1970e-02, -5.2688e-02,  5.0774e-02, -3.3654e-02,\n",
      "        -3.4828e-02, -5.9138e-02, -6.0549e-02,  2.9032e-02,  1.4579e-02,\n",
      "         6.0317e-02, -7.0894e-03, -5.9999e-02, -5.7782e-02,  5.3668e-02,\n",
      "        -6.2392e-02,  2.5460e-02,  2.7732e-02, -5.8520e-02,  8.0627e-03,\n",
      "         3.7720e-02,  1.6916e-02, -1.5563e-02,  5.7956e-03,  5.3603e-02,\n",
      "         3.2190e-02,  6.2414e-02, -2.8329e-03, -1.9528e-03,  1.6994e-02,\n",
      "        -1.0773e-02,  5.9869e-02,  6.2372e-02,  3.7580e-02, -1.0904e-02,\n",
      "        -4.3332e-02, -2.8316e-02,  3.9679e-02, -4.4894e-02, -4.3527e-02,\n",
      "        -2.2285e-02,  2.8826e-02,  3.1813e-02, -8.4762e-03, -5.9906e-02,\n",
      "         4.6485e-02, -2.0231e-03, -2.3491e-02,  4.4587e-02, -9.3570e-03,\n",
      "         3.9663e-02, -1.2258e-02, -1.8938e-02, -5.0310e-03, -4.8807e-02,\n",
      "        -2.5284e-02, -4.3773e-02, -1.4727e-03,  3.1207e-03, -5.2855e-02,\n",
      "         3.3342e-02,  1.9134e-02, -3.8864e-02, -5.2631e-02, -5.0487e-02,\n",
      "        -4.2719e-02,  2.9340e-03, -2.5142e-02, -3.5364e-02, -1.6401e-02,\n",
      "         5.1917e-03, -4.6016e-02,  6.9261e-03,  4.3869e-02, -5.6339e-02,\n",
      "        -4.2506e-05, -4.9749e-02,  2.1915e-02], requires_grad=True))\n",
      "('inf_mean.weight', Parameter containing:\n",
      "tensor([[ 0.0183,  0.0565, -0.0015,  ...,  0.0129, -0.0866,  0.0784],\n",
      "        [-0.0760,  0.0209, -0.0430,  ..., -0.0312, -0.0426, -0.0547],\n",
      "        [-0.0383, -0.0041, -0.0330,  ...,  0.0283, -0.0603, -0.0587],\n",
      "        ...,\n",
      "        [-0.0275,  0.0767,  0.0708,  ...,  0.0551,  0.0243, -0.0434],\n",
      "        [ 0.0706,  0.0504,  0.0704,  ..., -0.0222, -0.0588,  0.0678],\n",
      "        [ 0.0059, -0.0096,  0.0076,  ..., -0.0214, -0.0048, -0.0089]],\n",
      "       requires_grad=True))\n",
      "('inf_mean.bias', Parameter containing:\n",
      "tensor([ 0.0433,  0.0443, -0.0570, -0.0284, -0.0104,  0.0533, -0.0188,  0.0223,\n",
      "         0.0333, -0.0332,  0.0757, -0.0425,  0.0655,  0.0530,  0.0393,  0.0311,\n",
      "         0.0172, -0.0647,  0.0063,  0.0642, -0.0755,  0.0225, -0.0213,  0.0736,\n",
      "        -0.0561, -0.0274,  0.0492,  0.0495,  0.0631,  0.0248,  0.0292, -0.0015],\n",
      "       requires_grad=True))\n",
      "('inf_logvar.weight', Parameter containing:\n",
      "tensor([[ 0.0610, -0.0154,  0.0714,  ..., -0.0385, -0.0011, -0.0649],\n",
      "        [ 0.0606,  0.0468, -0.0085,  ...,  0.0087,  0.0094,  0.0051],\n",
      "        [ 0.0462, -0.0049, -0.0481,  ..., -0.0289, -0.0259, -0.0594],\n",
      "        ...,\n",
      "        [-0.0241, -0.0140,  0.0584,  ..., -0.0706, -0.0188, -0.0023],\n",
      "        [-0.0534,  0.0716, -0.0116,  ..., -0.0301, -0.0655,  0.0470],\n",
      "        [ 0.0407, -0.0545,  0.0401,  ...,  0.0746,  0.0578, -0.0161]],\n",
      "       requires_grad=True))\n",
      "('inf_logvar.bias', Parameter containing:\n",
      "tensor([-0.0574, -0.0781,  0.0004,  0.0086, -0.0276,  0.0872, -0.0346,  0.0840,\n",
      "        -0.0066, -0.0126,  0.0561, -0.0257, -0.0646,  0.0454, -0.0742,  0.0309,\n",
      "        -0.0793,  0.0385,  0.0840, -0.0218,  0.0698,  0.0646,  0.0591,  0.0536,\n",
      "         0.0540, -0.0757,  0.0485, -0.0014,  0.0474,  0.0471,  0.0102,  0.0792],\n",
      "       requires_grad=True))\n",
      "('mlp_a_x.linear0.weight', Parameter containing:\n",
      "tensor([[ 0.1736,  0.1371, -0.0673,  ...,  0.0471, -0.1720, -0.1379],\n",
      "        [-0.1192, -0.0887,  0.1447,  ...,  0.0404,  0.1687, -0.0130],\n",
      "        [-0.1397,  0.0504,  0.0049,  ...,  0.0591, -0.0078, -0.1628],\n",
      "        ...,\n",
      "        [-0.0133, -0.0134,  0.0766,  ..., -0.0730, -0.0898,  0.1224],\n",
      "        [ 0.0064,  0.1121, -0.0363,  ...,  0.0435,  0.1285, -0.0531],\n",
      "        [-0.1706,  0.0123,  0.0896,  ...,  0.0207,  0.0733,  0.0944]],\n",
      "       requires_grad=True))\n",
      "('mlp_a_x.linear0.bias', Parameter containing:\n",
      "tensor([ 1.0588e-01, -7.3045e-02,  5.3887e-03, -1.9460e-02, -1.0066e-01,\n",
      "         6.4279e-02, -7.4658e-03,  1.6124e-01,  1.5060e-01, -1.6754e-01,\n",
      "        -5.1128e-02, -1.1172e-01, -8.2518e-02,  9.3207e-02, -7.6454e-02,\n",
      "         7.6775e-02,  1.4720e-01, -9.4835e-02, -6.7763e-02, -2.9409e-02,\n",
      "         1.5861e-01, -1.4498e-01, -1.3631e-01, -2.0468e-02,  1.5459e-01,\n",
      "         1.3859e-01,  3.8168e-02, -3.4851e-02, -5.8114e-02,  5.0317e-03,\n",
      "         7.7742e-02, -5.5943e-02,  6.5170e-02,  1.5600e-01,  1.0818e-01,\n",
      "         7.6611e-02,  7.8161e-02,  5.2679e-02,  1.6547e-01,  1.3506e-01,\n",
      "        -1.0049e-01,  2.0715e-02,  1.4936e-01, -4.2153e-02, -6.7056e-02,\n",
      "        -7.4385e-03, -1.5797e-01, -1.3947e-01,  8.2597e-02,  4.9439e-02,\n",
      "         2.0459e-02, -1.2534e-01, -1.4017e-01,  1.5339e-01,  9.8510e-02,\n",
      "        -2.5602e-02,  1.1199e-01, -9.8443e-02, -7.2757e-02,  1.1839e-01,\n",
      "        -4.3704e-02, -1.3276e-01, -7.8087e-02, -1.1800e-01, -1.1332e-01,\n",
      "        -6.1839e-02, -2.4821e-02,  1.6955e-01, -1.7458e-01,  1.1938e-01,\n",
      "         1.0740e-02,  2.6737e-02, -9.2493e-02, -1.4253e-01,  4.3594e-02,\n",
      "         5.6779e-02,  5.1118e-02,  4.7081e-02, -1.4046e-01,  1.0566e-04,\n",
      "        -8.3420e-03, -1.2477e-01,  5.9240e-02,  1.0492e-02,  1.0107e-01,\n",
      "        -1.3671e-01,  1.0041e-01,  9.6194e-04, -1.2249e-01, -1.4650e-01,\n",
      "         6.1924e-02, -1.3925e-01, -8.6184e-02, -9.9446e-02, -1.0142e-01,\n",
      "        -8.6367e-02, -1.4433e-01,  3.2192e-02, -2.4408e-02,  3.7441e-02,\n",
      "         1.9771e-02,  3.0199e-02, -5.7306e-02, -9.4562e-02,  1.4634e-01,\n",
      "         9.9747e-02, -4.7858e-02, -2.3156e-02,  6.0540e-02,  7.3414e-02,\n",
      "         4.1482e-02, -1.3357e-01, -1.7467e-01, -3.7426e-03, -5.9118e-02,\n",
      "         4.8772e-02, -2.0867e-02, -1.7165e-01,  1.2142e-01, -1.1566e-01,\n",
      "        -1.3961e-01, -2.3381e-02, -2.4795e-02, -9.0305e-02,  1.6436e-01,\n",
      "        -1.5202e-01,  5.1546e-02,  2.5326e-02], requires_grad=True))\n",
      "('mlp_a_x.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.0216,  0.0605, -0.0638,  ..., -0.0496, -0.0389, -0.0239],\n",
      "        [ 0.0766, -0.0275, -0.0828,  ...,  0.0360,  0.0555, -0.0538],\n",
      "        [-0.0314, -0.0728,  0.0880,  ...,  0.0738, -0.0449, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0591,  0.0503,  0.0140,  ...,  0.0759,  0.0268,  0.0112],\n",
      "        [ 0.0823,  0.0243,  0.0475,  ...,  0.0201, -0.0316,  0.0613],\n",
      "        [-0.0478,  0.0023,  0.0620,  ..., -0.0853, -0.0747, -0.0339]],\n",
      "       requires_grad=True))\n",
      "('mlp_a_x.linear1.bias', Parameter containing:\n",
      "tensor([ 0.0045,  0.0415,  0.0245, -0.0025, -0.0175,  0.0340,  0.0082, -0.0391,\n",
      "         0.0074, -0.0614,  0.0716, -0.0683, -0.0195, -0.0583, -0.0617,  0.0814,\n",
      "        -0.0216, -0.0780, -0.0814,  0.0234, -0.0225,  0.0842,  0.0501,  0.0056,\n",
      "        -0.0038,  0.0800,  0.0233, -0.0410,  0.0043,  0.0480,  0.0293, -0.0138,\n",
      "         0.0008, -0.0060, -0.0575,  0.0407,  0.0456, -0.0260,  0.0146, -0.0478,\n",
      "        -0.0152,  0.0503,  0.0063,  0.0858, -0.0224,  0.0484, -0.0268,  0.0376,\n",
      "         0.0541, -0.0698,  0.0555, -0.0733,  0.0743,  0.0684, -0.0680, -0.0334,\n",
      "        -0.0341, -0.0069,  0.0786,  0.0427, -0.0689,  0.0042, -0.0621, -0.0544,\n",
      "         0.0420,  0.0802, -0.0556, -0.0803,  0.0616,  0.0214,  0.0127,  0.0880,\n",
      "        -0.0881,  0.0373, -0.0701,  0.0303, -0.0733, -0.0850,  0.0515,  0.0585,\n",
      "         0.0067, -0.0404,  0.0124,  0.0041, -0.0575, -0.0591,  0.0457, -0.0716,\n",
      "        -0.0097,  0.0077, -0.0862, -0.0034,  0.0745, -0.0338,  0.0720, -0.0126,\n",
      "        -0.0263, -0.0216, -0.0186,  0.0063,  0.0407,  0.0011,  0.0429, -0.0327,\n",
      "         0.0505, -0.0557,  0.0668,  0.0634,  0.0370,  0.0797,  0.0135,  0.0759,\n",
      "         0.0645, -0.0351, -0.0072,  0.0658,  0.0359, -0.0732,  0.0873, -0.0691,\n",
      "        -0.0476, -0.0483, -0.0762, -0.0355, -0.0115, -0.0080,  0.0383,  0.0295,\n",
      "         0.0749, -0.0287,  0.0472, -0.0878,  0.0347, -0.0581,  0.0194, -0.0043,\n",
      "        -0.0461,  0.0047, -0.0353, -0.0532, -0.0239, -0.0253, -0.0522, -0.0506,\n",
      "         0.0660, -0.0404, -0.0398, -0.0318, -0.0736, -0.0592, -0.0625, -0.0579,\n",
      "         0.0723, -0.0641,  0.0805,  0.0161, -0.0817, -0.0354, -0.0091, -0.0299,\n",
      "         0.0469,  0.0468, -0.0407,  0.0874,  0.0047,  0.0600,  0.0883, -0.0407,\n",
      "         0.0223, -0.0083,  0.0871, -0.0480, -0.0795,  0.0052, -0.0714, -0.0528,\n",
      "        -0.0664, -0.0759,  0.0722, -0.0215, -0.0112,  0.0557,  0.0052,  0.0015,\n",
      "        -0.0250, -0.0392,  0.0762,  0.0198, -0.0683,  0.0115,  0.0472, -0.0116,\n",
      "        -0.0779, -0.0747, -0.0840, -0.0038, -0.0131,  0.0630, -0.0865, -0.0761,\n",
      "         0.0641, -0.0652,  0.0867, -0.0291, -0.0108, -0.0127, -0.0409, -0.0511,\n",
      "         0.0522, -0.0478,  0.0697,  0.0848,  0.0456, -0.0266, -0.0409,  0.0759,\n",
      "         0.0421, -0.0533, -0.0531, -0.0550, -0.0678, -0.0629, -0.0604, -0.0489,\n",
      "         0.0105,  0.0338, -0.0615, -0.0319, -0.0400, -0.0021, -0.0124, -0.0646,\n",
      "        -0.0748,  0.0138,  0.0140, -0.0306,  0.0690, -0.0361,  0.0641,  0.0723,\n",
      "         0.0629, -0.0237,  0.0621,  0.0373, -0.0170, -0.0163, -0.0547,  0.0376,\n",
      "        -0.0384, -0.0618, -0.0508, -0.0423,  0.0714, -0.0496, -0.0773, -0.0836],\n",
      "       requires_grad=True))\n",
      "('gen_logvar.weight', Parameter containing:\n",
      "tensor([[ 0.0096, -0.0450, -0.0484,  ..., -0.0492, -0.0004, -0.0521],\n",
      "        [-0.0227,  0.0499,  0.0491,  ..., -0.0337,  0.0348, -0.0481],\n",
      "        [ 0.0086, -0.0366, -0.0160,  ..., -0.0143, -0.0277, -0.0306],\n",
      "        ...,\n",
      "        [-0.0443, -0.0087,  0.0168,  ..., -0.0204,  0.0150, -0.0100],\n",
      "        [-0.0079, -0.0009,  0.0490,  ...,  0.0006,  0.0267, -0.0498],\n",
      "        [ 0.0418, -0.0166, -0.0355,  ..., -0.0313, -0.0369,  0.0113]],\n",
      "       requires_grad=True))\n",
      "('gen_logvar.bias', Parameter containing:\n",
      "tensor([ 0.0407, -0.0451,  0.0270,  ...,  0.0621, -0.0549, -0.0331],\n",
      "       requires_grad=True))\n",
      "('rnn_alpha.weight_ih_l0', Parameter containing:\n",
      "tensor([[-0.0751, -0.0093,  0.0482,  ...,  0.0455, -0.0848, -0.1205],\n",
      "        [ 0.1344, -0.0812,  0.0045,  ..., -0.0349,  0.1012,  0.1241],\n",
      "        [-0.1322,  0.0853,  0.0284,  ..., -0.1177,  0.1402, -0.0105],\n",
      "        ...,\n",
      "        [-0.0317,  0.1210, -0.1088,  ..., -0.1125, -0.0027,  0.0542],\n",
      "        [ 0.0742, -0.0462,  0.0179,  ..., -0.0006, -0.0833,  0.0704],\n",
      "        [ 0.1048, -0.0212, -0.0678,  ..., -0.0170, -0.0031,  0.0045]],\n",
      "       requires_grad=True))\n",
      "('rnn_alpha.weight_hh_l0', Parameter containing:\n",
      "tensor([[ 0.0934, -0.1288,  0.0245,  ..., -0.0211, -0.0755, -0.0667],\n",
      "        [ 0.0931,  0.0806, -0.0820,  ...,  0.0286,  0.0990, -0.1251],\n",
      "        [-0.1017, -0.1242, -0.0735,  ...,  0.0945, -0.0441,  0.0542],\n",
      "        ...,\n",
      "        [ 0.0489, -0.0696, -0.0129,  ...,  0.0595, -0.1231,  0.0222],\n",
      "        [-0.1408,  0.0473, -0.0706,  ...,  0.0930,  0.1017,  0.0798],\n",
      "        [ 0.0240, -0.1245,  0.0379,  ..., -0.0294, -0.0684, -0.0562]],\n",
      "       requires_grad=True))\n",
      "('rnn_alpha.bias_ih_l0', Parameter containing:\n",
      "tensor([-0.0143,  0.0491, -0.1073,  0.0422, -0.0460, -0.1172,  0.1173,  0.0728,\n",
      "        -0.1398,  0.0397, -0.1305,  0.0942,  0.0835, -0.1021,  0.1372,  0.0148,\n",
      "        -0.0637, -0.0017,  0.1024, -0.0676, -0.1040,  0.0856,  0.0128, -0.0081,\n",
      "        -0.0952,  0.0827, -0.0846,  0.0753,  0.0585, -0.0472, -0.0023,  0.0167,\n",
      "        -0.0718, -0.0385, -0.0719,  0.1009, -0.0023,  0.0101,  0.1303, -0.0754,\n",
      "        -0.0024, -0.0774,  0.1286,  0.0663, -0.1390, -0.0164, -0.0923, -0.0865,\n",
      "         0.0284, -0.0277,  0.1186,  0.1394,  0.0555,  0.0407,  0.0761, -0.0575,\n",
      "        -0.1037, -0.0409,  0.0207, -0.1062,  0.0058, -0.0382, -0.0959, -0.0274,\n",
      "        -0.1286, -0.0288,  0.0013,  0.1150,  0.1291,  0.0270, -0.0084, -0.0153,\n",
      "         0.1000,  0.1162,  0.1261, -0.1260,  0.0625,  0.1185, -0.0530, -0.1210,\n",
      "        -0.0041, -0.1319, -0.0801,  0.0228, -0.0195, -0.0622, -0.0391,  0.0004,\n",
      "         0.0668, -0.0948,  0.0763,  0.0348, -0.0870,  0.0891,  0.0933,  0.1070,\n",
      "        -0.0089, -0.1056,  0.0828, -0.0045, -0.0121, -0.1392,  0.0751, -0.0907,\n",
      "         0.0191,  0.1094,  0.0134, -0.1310, -0.1196, -0.0822,  0.0593,  0.1271,\n",
      "         0.0759,  0.0879, -0.1380,  0.0695, -0.0481, -0.0681,  0.0837, -0.0614,\n",
      "        -0.1126, -0.1164, -0.1074,  0.1345,  0.0830,  0.1332,  0.1100,  0.1195,\n",
      "        -0.0020, -0.0472,  0.0305,  0.1145,  0.0969, -0.0711, -0.0493, -0.0099,\n",
      "         0.0335, -0.1297,  0.1138,  0.0872, -0.0273,  0.0717, -0.0373, -0.0976,\n",
      "         0.0566, -0.1328,  0.1083,  0.0038, -0.1160, -0.1288, -0.0926,  0.1163,\n",
      "         0.0957, -0.1040,  0.0939,  0.1328,  0.0303, -0.0148, -0.0743, -0.0951,\n",
      "         0.0056, -0.0114,  0.0452,  0.0978,  0.0387,  0.0953,  0.1205,  0.0051,\n",
      "        -0.0996,  0.0752,  0.1211,  0.1410, -0.0862,  0.0365, -0.0211, -0.0219,\n",
      "         0.0235, -0.0722, -0.0013, -0.0909, -0.0544,  0.1134, -0.1228, -0.0169,\n",
      "         0.0314, -0.1036, -0.1286, -0.0456, -0.0815,  0.0831, -0.0445,  0.0370,\n",
      "        -0.0324, -0.0284, -0.0836,  0.1317,  0.0316,  0.0497,  0.0587,  0.0921],\n",
      "       requires_grad=True))\n",
      "('rnn_alpha.bias_hh_l0', Parameter containing:\n",
      "tensor([-0.0942, -0.1326,  0.0248,  0.1393, -0.0370, -0.0801, -0.0643,  0.0691,\n",
      "        -0.0530,  0.0622,  0.1141, -0.0991, -0.1157,  0.0117, -0.1237, -0.0987,\n",
      "         0.0186, -0.0411,  0.0229, -0.1097, -0.0663, -0.0375, -0.0364, -0.0490,\n",
      "         0.0205, -0.0361, -0.0108, -0.1387, -0.1153, -0.0713,  0.0394, -0.0286,\n",
      "        -0.0706,  0.0218,  0.0840, -0.0072, -0.0391,  0.0926, -0.1068, -0.1118,\n",
      "        -0.0174,  0.0786,  0.0407, -0.0708, -0.0306,  0.0433,  0.0262, -0.0746,\n",
      "         0.0427, -0.0737, -0.0059, -0.0884,  0.0494, -0.0436,  0.0403,  0.0479,\n",
      "        -0.0803,  0.1305,  0.1347, -0.0239, -0.0470, -0.1184, -0.1065, -0.0485,\n",
      "        -0.1389,  0.1174, -0.1140,  0.0919,  0.0146, -0.0338,  0.0759, -0.0633,\n",
      "        -0.1012, -0.0875,  0.1217, -0.1386, -0.0114, -0.0503,  0.0051, -0.1387,\n",
      "         0.1130, -0.0673, -0.0838,  0.1338,  0.0243,  0.0277, -0.1362,  0.0684,\n",
      "        -0.0343, -0.0228,  0.0373,  0.1125,  0.0765,  0.0216,  0.0356,  0.0463,\n",
      "        -0.1061,  0.0211,  0.1217,  0.0204,  0.0722, -0.0829, -0.1330, -0.0745,\n",
      "         0.1293,  0.1251,  0.0423, -0.0295,  0.0436,  0.1402, -0.1150,  0.0148,\n",
      "         0.0637, -0.0849,  0.0644, -0.0398,  0.0812,  0.0198, -0.0850,  0.0255,\n",
      "         0.0086, -0.0080,  0.0555,  0.0882, -0.1164, -0.1016, -0.0863,  0.1267,\n",
      "         0.1157, -0.0970, -0.0079,  0.0391,  0.0572, -0.1338, -0.0265, -0.0779,\n",
      "         0.0745, -0.0847,  0.1078, -0.1099,  0.0795, -0.1080,  0.1171,  0.1061,\n",
      "         0.0653, -0.0772,  0.1155, -0.1140,  0.1064,  0.0625, -0.0528,  0.0371,\n",
      "        -0.1299,  0.0803, -0.0884,  0.1112,  0.0447,  0.0914,  0.0795, -0.0670,\n",
      "        -0.1000, -0.0217, -0.0945,  0.1400, -0.0517,  0.0613, -0.0958,  0.0926,\n",
      "        -0.1326, -0.1063, -0.1402, -0.0711, -0.0691,  0.0144, -0.0141, -0.0076,\n",
      "         0.0861, -0.1105,  0.0200,  0.0935, -0.1220, -0.0690,  0.0818, -0.0843,\n",
      "        -0.1277, -0.1044,  0.1181, -0.1050,  0.0799,  0.0713, -0.0896, -0.0405,\n",
      "         0.0868, -0.0668,  0.0716, -0.0397, -0.1258, -0.0666, -0.0697, -0.1141],\n",
      "       requires_grad=True))\n",
      "('mlp_alpha.0.weight', Parameter containing:\n",
      "tensor([[ 2.4204e-02,  1.1565e-01, -8.9919e-03, -5.3344e-02,  1.9273e-02,\n",
      "          6.7778e-02, -2.1187e-03,  6.8554e-02,  2.2950e-02,  3.3731e-03,\n",
      "         -9.0439e-02, -1.3482e-01,  9.2651e-02,  1.2378e-01,  1.1768e-01,\n",
      "          1.1825e-01,  6.7698e-02, -1.3631e-01,  7.7931e-02, -9.4752e-02,\n",
      "         -3.9774e-02,  8.6487e-02, -1.4138e-01,  9.5192e-02,  1.3963e-01,\n",
      "          1.1129e-02, -3.7290e-02, -1.1222e-01,  1.2803e-01, -4.0122e-02,\n",
      "         -1.0471e-01,  5.6850e-03, -1.1739e-01,  3.8160e-02,  5.3514e-02,\n",
      "         -1.2378e-01,  2.9198e-03,  6.5668e-02, -1.0584e-01, -7.5338e-02,\n",
      "         -7.2548e-02,  2.8348e-02, -7.4939e-02,  1.3106e-01,  5.9118e-02,\n",
      "          8.6875e-02,  4.5943e-02,  1.3072e-01, -9.1785e-02, -1.1854e-01],\n",
      "        [-2.2242e-03,  8.5578e-02,  1.0151e-01, -5.7288e-02, -3.7032e-02,\n",
      "          9.8641e-02, -5.7792e-02, -1.0354e-01, -1.1971e-01,  7.3513e-02,\n",
      "          1.2646e-01,  7.1205e-02,  8.9772e-02, -2.4972e-02,  1.3930e-01,\n",
      "         -8.5433e-02, -6.9390e-02,  7.8169e-02,  6.0156e-02,  2.3927e-02,\n",
      "          1.3444e-01,  1.8090e-02, -1.6164e-02, -5.1351e-02, -1.1619e-01,\n",
      "         -1.1739e-01, -6.9406e-02, -2.4620e-02, -5.5509e-02, -9.5827e-02,\n",
      "         -9.5155e-02, -4.9764e-02, -6.5551e-02,  7.8965e-02,  1.1939e-01,\n",
      "         -1.0349e-01,  1.0354e-01, -2.8695e-02,  1.3336e-01, -4.3907e-02,\n",
      "         -2.6556e-03,  9.3881e-02, -1.0797e-01,  4.0742e-02,  6.4674e-02,\n",
      "          3.4359e-02,  6.7203e-02, -1.3705e-01,  5.6089e-03, -3.8293e-02],\n",
      "        [-9.5803e-02, -9.3732e-02,  1.0236e-01, -5.6651e-02, -5.3212e-02,\n",
      "         -1.5915e-02, -4.3743e-02, -6.6627e-02, -9.2406e-02, -1.2674e-01,\n",
      "          9.6905e-02,  1.0334e-01,  1.4072e-01,  1.3517e-01, -1.0243e-01,\n",
      "          3.2026e-02, -7.1003e-02, -9.5954e-02,  6.9197e-02, -5.3325e-02,\n",
      "          1.5623e-02, -8.7819e-02, -1.0658e-02, -2.8239e-02, -3.0589e-02,\n",
      "         -6.5008e-02, -5.0791e-02, -5.6018e-02, -4.9411e-02, -8.1175e-02,\n",
      "          1.2415e-01,  1.3774e-01,  3.6199e-03,  3.8227e-02,  1.3647e-02,\n",
      "          1.8309e-02,  7.4959e-02,  2.1142e-03,  1.0530e-01,  1.3741e-02,\n",
      "          1.1109e-01,  1.1687e-01, -1.0260e-01, -7.9615e-02, -7.5789e-02,\n",
      "          6.3427e-02,  4.7629e-02,  5.6496e-02,  9.4103e-02,  8.6096e-02],\n",
      "        [-6.6927e-02, -4.0902e-02,  6.7352e-02, -8.1209e-02,  9.5207e-02,\n",
      "          1.2401e-01,  1.2298e-01, -1.6207e-02,  7.5752e-02,  1.3231e-01,\n",
      "          3.9488e-02,  4.2748e-02,  1.2030e-01, -1.3242e-01, -5.5125e-03,\n",
      "         -8.2971e-02,  1.1102e-01, -7.3949e-02,  9.7227e-02, -1.3905e-01,\n",
      "         -1.4025e-01,  2.5448e-02, -5.6507e-03,  2.7008e-02,  3.0717e-02,\n",
      "         -1.4005e-01,  3.4735e-02,  1.2507e-02, -1.2176e-01, -6.0380e-02,\n",
      "          1.3871e-01, -5.2193e-02, -1.1218e-03, -1.2993e-01, -1.0184e-01,\n",
      "          1.0150e-01,  1.2918e-01, -1.0345e-01,  1.4111e-01,  5.1389e-02,\n",
      "          1.3294e-01,  8.9358e-03,  1.0999e-01, -1.3187e-01,  2.7234e-02,\n",
      "         -6.9796e-02, -1.1142e-01, -8.2570e-02, -1.2306e-02, -1.2613e-01],\n",
      "        [-2.2863e-02, -1.2092e-02,  5.7434e-02,  1.1000e-01,  2.4361e-02,\n",
      "          6.2210e-02, -3.2566e-02, -9.9156e-02, -1.3733e-02,  3.8577e-02,\n",
      "          1.5176e-02,  6.3238e-02,  7.7391e-02,  4.6405e-02, -7.0911e-02,\n",
      "          3.2603e-02, -9.8134e-02,  6.7618e-02, -6.0274e-02, -2.4420e-02,\n",
      "          1.3965e-02, -1.1336e-02, -5.2048e-02, -7.0998e-03, -1.3354e-01,\n",
      "          7.1267e-02, -1.3813e-01, -7.9332e-02,  1.0499e-01,  1.0312e-01,\n",
      "         -5.2611e-02, -2.7055e-04,  1.9918e-02,  9.6639e-02,  5.5965e-02,\n",
      "         -1.0672e-01, -1.7284e-02,  4.7043e-02, -1.2277e-01,  1.0655e-01,\n",
      "          8.0761e-04, -6.7904e-02,  4.6276e-02, -5.7759e-02,  2.2057e-02,\n",
      "          3.3888e-02,  1.3101e-01,  5.3897e-02,  6.0552e-02, -6.4276e-02],\n",
      "        [ 2.9970e-02,  9.9206e-03, -3.6888e-02,  1.2134e-01, -8.2954e-02,\n",
      "          6.6861e-02,  1.3972e-01, -9.0870e-02,  7.5950e-02,  7.7377e-02,\n",
      "         -2.7106e-02,  7.3539e-02, -2.4242e-02,  1.1219e-01,  6.9313e-02,\n",
      "         -6.4808e-02,  4.2315e-02,  1.1046e-01, -1.3440e-01, -4.6702e-02,\n",
      "          6.1377e-02, -1.2913e-01, -1.9015e-02,  1.0668e-01, -2.1439e-02,\n",
      "          9.8837e-02,  3.6265e-02, -2.3181e-02,  4.5056e-02,  5.1710e-02,\n",
      "          1.0540e-01, -2.3748e-02, -2.7819e-02, -8.6204e-02, -1.2057e-02,\n",
      "          6.6329e-02,  1.7263e-02, -1.3429e-01,  8.0463e-02,  5.6668e-03,\n",
      "         -1.1551e-01, -1.2938e-01, -2.7012e-02, -5.9784e-02,  4.5439e-02,\n",
      "          2.8750e-02,  4.8044e-02,  1.3871e-01,  3.1227e-03,  1.1545e-03],\n",
      "        [ 1.2291e-01,  4.0140e-02, -2.1005e-03,  7.1372e-02, -6.4984e-05,\n",
      "          3.7515e-02, -9.3537e-02, -7.3996e-02,  1.4075e-01,  4.3489e-02,\n",
      "          8.5296e-03,  1.1684e-01,  1.1770e-01,  7.7432e-02, -3.5142e-02,\n",
      "         -1.2218e-01, -9.6986e-02, -7.3655e-02, -2.1048e-02, -9.9179e-02,\n",
      "         -3.0129e-02,  1.0988e-01,  3.2957e-02, -9.7438e-02,  1.3913e-01,\n",
      "         -6.5247e-02, -1.1373e-01, -5.7221e-02, -7.3258e-02, -1.0175e-02,\n",
      "          1.3887e-02,  1.1115e-01, -3.1583e-02, -1.5522e-02,  3.5051e-02,\n",
      "          1.2346e-01,  8.6153e-02,  1.3869e-01,  4.1484e-02,  1.3720e-01,\n",
      "          5.1754e-02,  1.1828e-01, -4.0549e-02,  1.3297e-01, -1.3875e-01,\n",
      "          4.0663e-02, -2.9094e-02, -2.0416e-02,  1.3802e-01,  1.4327e-02],\n",
      "        [ 8.4088e-02,  8.7817e-02,  5.9285e-02, -5.2573e-02,  2.7106e-02,\n",
      "         -6.5618e-02, -5.2085e-02, -7.6104e-02,  1.2078e-01,  1.3836e-01,\n",
      "          1.1341e-01,  4.4319e-02, -1.0097e-01,  2.6512e-02, -1.0058e-01,\n",
      "         -7.7034e-02, -4.4248e-02,  1.0187e-01, -1.2158e-01,  7.7693e-02,\n",
      "          2.2517e-02, -6.0343e-02,  8.1258e-04,  6.0385e-02, -1.0695e-01,\n",
      "          1.5586e-02,  5.5500e-03, -5.1296e-02,  1.1113e-02,  3.5365e-02,\n",
      "         -2.6566e-02,  5.8697e-02, -1.0531e-02,  2.6358e-02,  8.9897e-02,\n",
      "          8.9962e-02, -9.2653e-02,  6.2601e-02,  1.2059e-01, -1.4592e-02,\n",
      "          3.6234e-03,  4.5423e-03,  4.2961e-02,  2.7140e-02,  8.1395e-02,\n",
      "         -8.9645e-02,  9.3965e-02, -3.7246e-02,  6.5116e-02,  1.2612e-01],\n",
      "        [-1.3322e-01,  4.2453e-02,  1.3821e-01, -2.5357e-02, -1.0690e-01,\n",
      "         -1.4914e-03, -1.3843e-01, -3.2264e-02, -6.9714e-02,  3.9815e-02,\n",
      "          2.7798e-02,  8.8988e-02, -9.3017e-02, -3.4726e-02,  9.3864e-02,\n",
      "         -5.1553e-02, -9.2457e-02, -1.0853e-02, -1.2273e-01,  9.2365e-02,\n",
      "          1.0526e-01,  2.9287e-02, -1.1708e-01, -1.3598e-02, -1.8978e-02,\n",
      "         -1.2681e-01, -4.2132e-02, -9.1498e-02,  1.1717e-01,  9.6003e-02,\n",
      "         -3.2308e-02, -3.9949e-02,  1.1157e-01, -8.8941e-02,  1.3911e-01,\n",
      "         -6.6444e-02, -5.3625e-03, -1.0240e-01, -5.0128e-02,  5.2941e-02,\n",
      "          5.4498e-02, -6.3230e-02, -2.4735e-02,  3.3397e-02, -9.3049e-03,\n",
      "         -4.8737e-02, -3.6799e-02, -1.1373e-01,  6.4101e-02, -2.4359e-02],\n",
      "        [-1.3494e-01,  5.2009e-02,  7.1373e-02, -1.0494e-01,  2.4551e-02,\n",
      "         -1.1455e-01, -2.6570e-02, -4.2921e-02, -7.3235e-02,  1.4905e-02,\n",
      "         -4.8300e-02,  1.0736e-01, -9.6552e-02, -1.0355e-01,  4.2225e-02,\n",
      "          2.6917e-02,  1.7439e-02, -5.3619e-02, -1.3550e-02, -8.4092e-03,\n",
      "          8.2136e-02, -1.2260e-01,  6.5819e-02,  3.6155e-02,  3.2116e-02,\n",
      "         -8.7996e-02, -1.3940e-01, -1.3067e-01, -5.4530e-02,  8.5975e-02,\n",
      "          6.8606e-02,  7.9326e-02,  5.2318e-02, -6.5533e-02, -1.2356e-01,\n",
      "         -5.5475e-02,  1.1594e-01,  2.4022e-02, -5.5432e-02, -1.5589e-02,\n",
      "          7.8571e-04,  1.0314e-01, -1.0788e-01,  6.4849e-02,  2.0428e-02,\n",
      "          1.1071e-01, -4.2133e-02, -2.9283e-02,  7.5751e-02,  1.2335e-01]],\n",
      "       requires_grad=True))\n",
      "('mlp_alpha.0.bias', Parameter containing:\n",
      "tensor([ 0.0026, -0.1270, -0.0126, -0.0042,  0.0878, -0.0165,  0.0233, -0.1052,\n",
      "        -0.0810,  0.0509], requires_grad=True))\n",
      "initialising optim...\n",
      "done\n",
      "only vae...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:10,  1.07s/it]\n",
      "5it [00:01,  3.07it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "yay!\n",
      "Training loss -3.1586523056030273 Validation loss -23.257054443359376\n",
      "only vae...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:09,  1.05it/s]\n",
      "5it [00:01,  3.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "yay!\n",
      "Training loss -28.36717727661133 Validation loss -32.742413940429685\n",
      "only vae...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:09,  1.06it/s]\n",
      "5it [00:01,  3.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "yay!\n",
      "Training loss -32.62704162597656 Validation loss -33.935776977539064\n",
      "vae + kf...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:10,  1.00s/it]\n",
      "5it [00:01,  2.83it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss -33.05788543701172 Validation loss -30.612090454101562\n",
      "vae + kf...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:09,  1.11it/s]\n",
      "5it [00:01,  3.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss -30.604740295410156 Validation loss -29.328719482421874\n",
      "all...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:09,  1.10it/s]\n",
      "5it [00:01,  3.19it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss -29.718880920410157 Validation loss -29.396651611328124\n",
      "all...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:08,  1.12it/s]\n",
      "5it [00:01,  2.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss -29.66496337890625 Validation loss -29.378226318359374\n",
      "all...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:09,  1.11it/s]\n",
      "5it [00:01,  2.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss -29.69298126220703 Validation loss -29.379577026367187\n",
      "all...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:09,  1.03it/s]\n",
      "5it [00:01,  3.07it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss -29.696949462890625 Validation loss -29.309982299804688\n",
      "all...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:10,  1.02s/it]\n",
      "5it [00:01,  3.28it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss -29.705748901367187 Validation loss -29.270011596679687\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_vid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "# generate audio with model state in cache\r\n",
    "# reconstructed audio will be saved in the same path as input audio file, named as 'audio_001_recon.wav'\r\n",
    "audio_ref = 'audio_001.wav'\r\n",
    "learning_algo.generate(audio_orig=audio_ref, audio_recon=None, state_dict_file=None)\r\n",
    "\r\n",
    "# generate audio with given model state\r\n",
    "# reconstructed audio will be saved in the given path\r\n",
    "audio_recon = 'recon/audio_001_recon.wav'\r\n",
    "model_state = 'model_state.pt'\r\n",
    "learning_algo.generate(audio_orig=audio_ref, audio_recon=audio_recon, state_dict_file=model_state)\r\n",
    "\r\n",
    "# evaluate audio quality with model state in cache\r\n",
    "score_rmse = learning_algo.eval(audio_ref=audio_ref, audio_est=audio_recon, metric='rmse') # only RMSE\r\n",
    "score_rmse, score_pesq, score_stoi = learning_algo.eval(audio_ref=audio_ref, audio_est=audio_recon, metric='all') # both RMSE, PESQ and STOI\r\n",
    "\r\n",
    "# test model on test dataset with model state in cache\r\n",
    "test_data_dir = 'data_to_test'\r\n",
    "list_score_rmse, list_score_pesq, list_score_stoi = learning_algo.test(data_dir=test_data_dir, state_dict_file=None)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7a650d791d0a1d035b66682f8967f04fed3045153a1ba3c3bfeefd2541b18a6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}